{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\HP\\\\python\\\\Revision Folder'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########################################################################\n",
    "#\n",
    "# Functions for downloading and extracting data-files from the internet.\n",
    "#\n",
    "# Implemented in Python 3.5\n",
    "#\n",
    "########################################################################\n",
    "#\n",
    "# This file is part of the TensorFlow Tutorials available at:\n",
    "#\n",
    "# https://github.com/Hvass-Labs/TensorFlow-Tutorials\n",
    "#\n",
    "# Published under the MIT License. See the file LICENSE for details.\n",
    "#\n",
    "# Copyright 2016 by Magnus Erik Hvass Pedersen\n",
    "#\n",
    "########################################################################\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import urllib.request\n",
    "import tarfile\n",
    "import zipfile\n",
    "\n",
    "########################################################################\n",
    "\n",
    "\n",
    "def _print_download_progress(count, block_size, total_size):\n",
    "    \"\"\"\n",
    "    Function used for printing the download progress.\n",
    "    Used as a call-back function in maybe_download_and_extract().\n",
    "    \"\"\"\n",
    "\n",
    "    # Percentage completion.\n",
    "    pct_complete = float(count * block_size) / total_size\n",
    "\n",
    "    # Limit it because rounding errors may cause it to exceed 100%.\n",
    "    pct_complete = min(1.0, pct_complete)\n",
    "\n",
    "    # Status-message. Note the \\r which means the line should overwrite itself.\n",
    "    msg = \"\\r- Download progress: {0:.1%}\".format(pct_complete)\n",
    "\n",
    "    # Print it.\n",
    "    sys.stdout.write(msg)\n",
    "    sys.stdout.flush()\n",
    "\n",
    "\n",
    "########################################################################\n",
    "\n",
    "def download(base_url, filename, download_dir):\n",
    "    \"\"\"\n",
    "    Download the given file if it does not already exist in the download_dir.\n",
    "    :param base_url: The internet URL without the filename.\n",
    "    :param filename: The filename that will be added to the base_url.\n",
    "    :param download_dir: Local directory for storing the file.\n",
    "    :return: Nothing.\n",
    "    \"\"\"\n",
    "\n",
    "    # Path for local file.\n",
    "    save_path = os.path.join(download_dir, filename)\n",
    "\n",
    "    # Check if the file already exists, otherwise we need to download it now.\n",
    "    if not os.path.exists(save_path):\n",
    "        # Check if the download directory exists, otherwise create it.\n",
    "        if not os.path.exists(download_dir):\n",
    "            os.makedirs(download_dir)\n",
    "\n",
    "        print(\"Downloading\", filename, \"...\")\n",
    "\n",
    "        # Download the file from the internet.\n",
    "        url = base_url + filename\n",
    "        file_path, _ = urllib.request.urlretrieve(url=url,\n",
    "                                                  filename=save_path,\n",
    "                                                  reporthook=_print_download_progress)\n",
    "\n",
    "        print(\" Done!\")\n",
    "\n",
    "\n",
    "def maybe_download_and_extract(url, download_dir):\n",
    "    \"\"\"\n",
    "    Download and extract the data if it doesn't already exist.\n",
    "    Assumes the url is a tar-ball file.\n",
    "    :param url:\n",
    "        Internet URL for the tar-file to download.\n",
    "        Example: \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n",
    "    :param download_dir:\n",
    "        Directory where the downloaded file is saved.\n",
    "        Example: \"data/CIFAR-10/\"\n",
    "    :return:\n",
    "        Nothing.\n",
    "    \"\"\"\n",
    "\n",
    "    # Filename for saving the file downloaded from the internet.\n",
    "    # Use the filename from the URL and add it to the download_dir.\n",
    "    filename = url.split('/')[-1]\n",
    "    file_path = os.path.join(download_dir, filename)\n",
    "\n",
    "    # Check if the file already exists.\n",
    "    # If it exists then we assume it has also been extracted,\n",
    "    # otherwise we need to download and extract it now.\n",
    "    if not os.path.exists(file_path):\n",
    "        # Check if the download directory exists, otherwise create it.\n",
    "        if not os.path.exists(download_dir):\n",
    "            os.makedirs(download_dir)\n",
    "\n",
    "        # Download the file from the internet.\n",
    "        file_path, _ = urllib.request.urlretrieve(url=url,\n",
    "                                                  filename=file_path,\n",
    "                                                  reporthook=_print_download_progress)\n",
    "\n",
    "        print()\n",
    "        print(\"Download finished. Extracting files.\")\n",
    "\n",
    "        if file_path.endswith(\".zip\"):\n",
    "            # Unpack the zip-file.\n",
    "            zipfile.ZipFile(file=file_path, mode=\"r\").extractall(download_dir)\n",
    "        elif file_path.endswith((\".tar.gz\", \".tgz\")):\n",
    "            # Unpack the tar-ball.\n",
    "            tarfile.open(name=file_path, mode=\"r:gz\").extractall(download_dir)\n",
    "\n",
    "        print(\"Done.\")\n",
    "    else:\n",
    "        print(\"Data has apparently already been downloaded and unpacked.\")\n",
    "\n",
    "\n",
    "########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = \"data/IMDB/\"\n",
    "\n",
    "# URL for the data-set on the internet.\n",
    "data_url = \"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Download progress: 100.0%\n",
      "Download finished. Extracting files.\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "#downloading data\n",
    "maybe_download_and_extract(data_url,data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########################################################################\n",
    "#\n",
    "# Functions for downloading the IMDB Review data-set from the internet\n",
    "# and loading it into memory.\n",
    "#\n",
    "# Implemented in Python 3.6\n",
    "#\n",
    "# Usage:\n",
    "# 1) Set the variable data_dir with the desired storage directory.\n",
    "# 2) Call maybe_download_and_extract() to download the data-set\n",
    "#    if it is not already located in the given data_dir.\n",
    "# 3) Call load_data(train=True) to load the training-set.\n",
    "# 4) Call load_data(train=False) to load the test-set.\n",
    "# 5) Use the returned data in your own program.\n",
    "#\n",
    "# Format:\n",
    "# The IMDB Review data-set consists of 50000 reviews of movies\n",
    "# that are split into 25000 reviews for the training- and test-set,\n",
    "# and each of those is split into 12500 positive and 12500 negative reviews.\n",
    "# These are returned as lists of strings by the load_data() function.\n",
    "#\n",
    "########################################################################\n",
    "#\n",
    "# This file is part of the TensorFlow Tutorials available at:\n",
    "#\n",
    "# https://github.com/Hvass-Labs/TensorFlow-Tutorials\n",
    "#\n",
    "# Published under the MIT License. See the file LICENSE for details.\n",
    "#\n",
    "# Copyright 2018 by Magnus Erik Hvass Pedersen\n",
    "#\n",
    "########################################################################\n",
    "\n",
    "import os\n",
    "import download\n",
    "import glob\n",
    "\n",
    "########################################################################\n",
    "\n",
    "# Directory where you want to download and save the data-set.\n",
    "# Set this before you start calling any of the functions below.\n",
    "data_dir = \"data/IMDB/\"\n",
    "\n",
    "# URL for the data-set on the internet.\n",
    "data_url = \"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
    "\n",
    "\n",
    "########################################################################\n",
    "# Private helper-functions.\n",
    "\n",
    "def _read_text_file(path):\n",
    "    \"\"\"\n",
    "    Read and return all the contents of the text-file with the given path.\n",
    "    It is returned as a single string where all lines are concatenated.\n",
    "    \"\"\"\n",
    "\n",
    "    with open(path, 'rt',encoding = 'latin1') as file:\n",
    "        # Read a list of strings.\n",
    "        lines = file.readlines()\n",
    "\n",
    "        # Concatenate to a single string.\n",
    "        text = \" \".join(lines)\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "########################################################################\n",
    "# Public functions that you may call to download the data-set from\n",
    "# the internet and load the data into memory.\n",
    "\n",
    "\n",
    "def maybe_download_and_extract():\n",
    "    \"\"\"\n",
    "    Download and extract the IMDB Review data-set if it doesn't already exist\n",
    "    in data_dir (set this variable first to the desired directory).\n",
    "    \"\"\"\n",
    "\n",
    "    download.maybe_download_and_extract(url=data_url, download_dir=data_dir)\n",
    "\n",
    "\n",
    "def load_data(train=True):\n",
    "    \"\"\"\n",
    "    Load all the data from the IMDB Review data-set for sentiment analysis.\n",
    "    :param train: Boolean whether to load the training-set (True)\n",
    "                  or the test-set (False).\n",
    "    :return:      A list of all the reviews as text-strings,\n",
    "                  and a list of the corresponding sentiments\n",
    "                  where 1.0 is positive and 0.0 is negative.\n",
    "    \"\"\"\n",
    "\n",
    "    # Part of the path-name for either training or test-set.\n",
    "    train_test_path = \"train\" if train else \"test\"\n",
    "\n",
    "    # Base-directory where the extracted data is located.\n",
    "    dir_base = os.path.join(data_dir, \"aclImdb\", train_test_path)\n",
    "\n",
    "    # Filename-patterns for the data-files.\n",
    "    path_pattern_pos = os.path.join(dir_base, \"pos\", \"*.txt\")\n",
    "    path_pattern_neg = os.path.join(dir_base, \"neg\", \"*.txt\")\n",
    "\n",
    "    # Get lists of all the file-paths for the data.\n",
    "    paths_pos = glob.glob(path_pattern_pos)\n",
    "    paths_neg = glob.glob(path_pattern_neg)\n",
    "\n",
    "    # Read all the text-files.\n",
    "    data_pos = [_read_text_file(path) for path in paths_pos]\n",
    "    data_neg = [_read_text_file(path) for path in paths_neg]\n",
    "\n",
    "    # Concatenate the positive and negative data.\n",
    "    x = data_pos + data_neg\n",
    "\n",
    "    # Create a list of the sentiments for the text-data.\n",
    "    # 1.0 is a positive sentiment, 0.0 is a negative sentiment.\n",
    "    y = [1.0] * len(data_pos) + [0.0] * len(data_neg)\n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loading data\n",
    "X_train_text,y_train = load_data(train = True)\n",
    "X_test_text,y_test = load_data(train = False)\n",
    "#list of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school life, such as \"Teachers\". My 35 years in the teaching profession lead me to believe that Bromwell High\\'s satire is much closer to reality than is \"Teachers\". The scramble to survive financially, the insightful students who can see right through their pathetic teachers\\' pomp, the pettiness of the whole situation, all remind me of the schools I knew and their students. When I saw the episode in which a student repeatedly tried to burn down the school, I immediately recalled ......... at .......... High. A classic line: INSPECTOR: I\\'m here to sack one of your teachers. STUDENT: Welcome to Bromwell High. I expect that many adults of my age think that Bromwell High is far fetched. What a pity that it isn\\'t!',\n",
       " 'Homelessness (or Houselessness as George Carlin stated) has been an issue for years but never a plan to help those on the street that were once considered human who did everything from going to school, work, or vote for the matter. Most people think of the homeless as just a lost cause while worrying about things such as racism, the war on Iraq, pressuring kids to succeed, technology, the elections, inflation, or worrying if they\\'ll be next to end up on the streets.<br /><br />But what if you were given a bet to live on the streets for a month without the luxuries you once had from a home, the entertainment sets, a bathroom, pictures on the wall, a computer, and everything you once treasure to see what it\\'s like to be homeless? That is Goddard Bolt\\'s lesson.<br /><br />Mel Brooks (who directs) who stars as Bolt plays a rich man who has everything in the world until deciding to make a bet with a sissy rival (Jeffery Tambor) to see if he can live in the streets for thirty days without the luxuries; if Bolt succeeds, he can do what he wants with a future project of making more buildings. The bet\\'s on where Bolt is thrown on the street with a bracelet on his leg to monitor his every move where he can\\'t step off the sidewalk. He\\'s given the nickname Pepto by a vagrant after it\\'s written on his forehead where Bolt meets other characters including a woman by the name of Molly (Lesley Ann Warren) an ex-dancer who got divorce before losing her home, and her pals Sailor (Howard Morris) and Fumes (Teddy Wilson) who are already used to the streets. They\\'re survivors. Bolt isn\\'t. He\\'s not used to reaching mutual agreements like he once did when being rich where it\\'s fight or flight, kill or be killed.<br /><br />While the love connection between Molly and Bolt wasn\\'t necessary to plot, I found \"Life Stinks\" to be one of Mel Brooks\\' observant films where prior to being a comedy, it shows a tender side compared to his slapstick work such as Blazing Saddles, Young Frankenstein, or Spaceballs for the matter, to show what it\\'s like having something valuable before losing it the next day or on the other hand making a stupid bet like all rich people do when they don\\'t know what to do with their money. Maybe they should give it to the homeless instead of using it like Monopoly money.<br /><br />Or maybe this film will inspire you to help others.']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_text[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 1.0]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_words = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words = num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_text = X_train_text + X_test_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#giving each word a number based on most frequent word\n",
    "tokenizer.fit_on_texts(data_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1,\n",
       " 'and': 2,\n",
       " 'a': 3,\n",
       " 'of': 4,\n",
       " 'to': 5,\n",
       " 'is': 6,\n",
       " 'br': 7,\n",
       " 'in': 8,\n",
       " 'it': 9,\n",
       " 'i': 10,\n",
       " 'this': 11,\n",
       " 'that': 12,\n",
       " 'was': 13,\n",
       " 'as': 14,\n",
       " 'for': 15,\n",
       " 'with': 16,\n",
       " 'movie': 17,\n",
       " 'but': 18,\n",
       " 'film': 19,\n",
       " 'on': 20,\n",
       " 'not': 21,\n",
       " 'you': 22,\n",
       " 'are': 23,\n",
       " 'his': 24,\n",
       " 'have': 25,\n",
       " 'be': 26,\n",
       " 'one': 27,\n",
       " 'he': 28,\n",
       " 'all': 29,\n",
       " 'at': 30,\n",
       " 'by': 31,\n",
       " 'an': 32,\n",
       " 'they': 33,\n",
       " 'so': 34,\n",
       " 'who': 35,\n",
       " 'from': 36,\n",
       " 'like': 37,\n",
       " 'or': 38,\n",
       " 'just': 39,\n",
       " 'her': 40,\n",
       " 'out': 41,\n",
       " 'about': 42,\n",
       " 'if': 43,\n",
       " \"it's\": 44,\n",
       " 'has': 45,\n",
       " 'there': 46,\n",
       " 'some': 47,\n",
       " 'what': 48,\n",
       " 'good': 49,\n",
       " 'when': 50,\n",
       " 'more': 51,\n",
       " 'very': 52,\n",
       " 'up': 53,\n",
       " 'no': 54,\n",
       " 'time': 55,\n",
       " 'my': 56,\n",
       " 'even': 57,\n",
       " 'would': 58,\n",
       " 'she': 59,\n",
       " 'which': 60,\n",
       " 'only': 61,\n",
       " 'really': 62,\n",
       " 'see': 63,\n",
       " 'story': 64,\n",
       " 'their': 65,\n",
       " 'had': 66,\n",
       " 'can': 67,\n",
       " 'me': 68,\n",
       " 'well': 69,\n",
       " 'were': 70,\n",
       " 'than': 71,\n",
       " 'much': 72,\n",
       " 'we': 73,\n",
       " 'bad': 74,\n",
       " 'been': 75,\n",
       " 'get': 76,\n",
       " 'do': 77,\n",
       " 'great': 78,\n",
       " 'other': 79,\n",
       " 'will': 80,\n",
       " 'also': 81,\n",
       " 'into': 82,\n",
       " 'people': 83,\n",
       " 'because': 84,\n",
       " 'how': 85,\n",
       " 'first': 86,\n",
       " 'him': 87,\n",
       " 'most': 88,\n",
       " \"don't\": 89,\n",
       " 'made': 90,\n",
       " 'then': 91,\n",
       " 'its': 92,\n",
       " 'them': 93,\n",
       " 'make': 94,\n",
       " 'way': 95,\n",
       " 'too': 96,\n",
       " 'movies': 97,\n",
       " 'could': 98,\n",
       " 'any': 99,\n",
       " 'after': 100,\n",
       " 'think': 101,\n",
       " 'characters': 102,\n",
       " 'watch': 103,\n",
       " 'films': 104,\n",
       " 'two': 105,\n",
       " 'many': 106,\n",
       " 'seen': 107,\n",
       " 'character': 108,\n",
       " 'being': 109,\n",
       " 'never': 110,\n",
       " 'plot': 111,\n",
       " 'love': 112,\n",
       " 'acting': 113,\n",
       " 'life': 114,\n",
       " 'did': 115,\n",
       " 'best': 116,\n",
       " 'where': 117,\n",
       " 'know': 118,\n",
       " 'show': 119,\n",
       " 'little': 120,\n",
       " 'over': 121,\n",
       " 'off': 122,\n",
       " 'ever': 123,\n",
       " 'does': 124,\n",
       " 'your': 125,\n",
       " 'better': 126,\n",
       " 'end': 127,\n",
       " 'man': 128,\n",
       " 'scene': 129,\n",
       " 'still': 130,\n",
       " 'say': 131,\n",
       " 'these': 132,\n",
       " 'here': 133,\n",
       " 'scenes': 134,\n",
       " 'why': 135,\n",
       " 'while': 136,\n",
       " 'something': 137,\n",
       " 'such': 138,\n",
       " 'go': 139,\n",
       " 'through': 140,\n",
       " 'back': 141,\n",
       " 'should': 142,\n",
       " 'those': 143,\n",
       " 'real': 144,\n",
       " \"i'm\": 145,\n",
       " 'now': 146,\n",
       " 'watching': 147,\n",
       " 'thing': 148,\n",
       " \"doesn't\": 149,\n",
       " 'actors': 150,\n",
       " 'though': 151,\n",
       " 'funny': 152,\n",
       " 'years': 153,\n",
       " \"didn't\": 154,\n",
       " 'old': 155,\n",
       " '10': 156,\n",
       " 'another': 157,\n",
       " 'work': 158,\n",
       " 'before': 159,\n",
       " 'actually': 160,\n",
       " 'nothing': 161,\n",
       " 'makes': 162,\n",
       " 'look': 163,\n",
       " 'director': 164,\n",
       " 'find': 165,\n",
       " 'going': 166,\n",
       " 'same': 167,\n",
       " 'new': 168,\n",
       " 'lot': 169,\n",
       " 'every': 170,\n",
       " 'few': 171,\n",
       " 'again': 172,\n",
       " 'part': 173,\n",
       " 'cast': 174,\n",
       " 'down': 175,\n",
       " 'us': 176,\n",
       " 'things': 177,\n",
       " 'want': 178,\n",
       " 'quite': 179,\n",
       " 'pretty': 180,\n",
       " 'world': 181,\n",
       " 'horror': 182,\n",
       " 'around': 183,\n",
       " 'seems': 184,\n",
       " \"can't\": 185,\n",
       " 'young': 186,\n",
       " 'take': 187,\n",
       " 'however': 188,\n",
       " 'got': 189,\n",
       " 'thought': 190,\n",
       " 'big': 191,\n",
       " 'fact': 192,\n",
       " 'enough': 193,\n",
       " 'long': 194,\n",
       " 'both': 195,\n",
       " \"that's\": 196,\n",
       " 'give': 197,\n",
       " \"i've\": 198,\n",
       " 'own': 199,\n",
       " 'may': 200,\n",
       " 'between': 201,\n",
       " 'comedy': 202,\n",
       " 'right': 203,\n",
       " 'series': 204,\n",
       " 'action': 205,\n",
       " 'must': 206,\n",
       " 'music': 207,\n",
       " 'without': 208,\n",
       " 'times': 209,\n",
       " 'saw': 210,\n",
       " 'always': 211,\n",
       " 'original': 212,\n",
       " \"isn't\": 213,\n",
       " 'role': 214,\n",
       " 'come': 215,\n",
       " 'almost': 216,\n",
       " 'gets': 217,\n",
       " 'interesting': 218,\n",
       " 'guy': 219,\n",
       " 'point': 220,\n",
       " 'done': 221,\n",
       " \"there's\": 222,\n",
       " 'whole': 223,\n",
       " 'least': 224,\n",
       " 'far': 225,\n",
       " 'bit': 226,\n",
       " 'script': 227,\n",
       " 'minutes': 228,\n",
       " 'feel': 229,\n",
       " '2': 230,\n",
       " 'anything': 231,\n",
       " 'making': 232,\n",
       " 'might': 233,\n",
       " 'since': 234,\n",
       " 'am': 235,\n",
       " 'family': 236,\n",
       " \"he's\": 237,\n",
       " 'last': 238,\n",
       " 'probably': 239,\n",
       " 'tv': 240,\n",
       " 'performance': 241,\n",
       " 'kind': 242,\n",
       " 'away': 243,\n",
       " 'yet': 244,\n",
       " 'fun': 245,\n",
       " 'worst': 246,\n",
       " 'sure': 247,\n",
       " 'rather': 248,\n",
       " 'hard': 249,\n",
       " 'anyone': 250,\n",
       " 'girl': 251,\n",
       " 'each': 252,\n",
       " 'played': 253,\n",
       " 'day': 254,\n",
       " 'found': 255,\n",
       " 'looking': 256,\n",
       " 'woman': 257,\n",
       " 'screen': 258,\n",
       " 'although': 259,\n",
       " 'our': 260,\n",
       " 'especially': 261,\n",
       " 'believe': 262,\n",
       " 'having': 263,\n",
       " 'trying': 264,\n",
       " 'course': 265,\n",
       " 'dvd': 266,\n",
       " 'everything': 267,\n",
       " 'set': 268,\n",
       " 'goes': 269,\n",
       " 'comes': 270,\n",
       " 'put': 271,\n",
       " 'ending': 272,\n",
       " 'maybe': 273,\n",
       " 'place': 274,\n",
       " 'book': 275,\n",
       " 'shows': 276,\n",
       " 'three': 277,\n",
       " 'worth': 278,\n",
       " 'different': 279,\n",
       " 'main': 280,\n",
       " 'once': 281,\n",
       " 'sense': 282,\n",
       " 'american': 283,\n",
       " 'reason': 284,\n",
       " 'looks': 285,\n",
       " 'effects': 286,\n",
       " 'watched': 287,\n",
       " 'play': 288,\n",
       " 'true': 289,\n",
       " 'money': 290,\n",
       " 'actor': 291,\n",
       " \"wasn't\": 292,\n",
       " 'job': 293,\n",
       " 'together': 294,\n",
       " 'war': 295,\n",
       " 'someone': 296,\n",
       " 'plays': 297,\n",
       " 'instead': 298,\n",
       " 'high': 299,\n",
       " 'during': 300,\n",
       " 'said': 301,\n",
       " 'year': 302,\n",
       " 'half': 303,\n",
       " 'everyone': 304,\n",
       " 'later': 305,\n",
       " 'takes': 306,\n",
       " '1': 307,\n",
       " 'seem': 308,\n",
       " 'audience': 309,\n",
       " 'special': 310,\n",
       " 'beautiful': 311,\n",
       " 'left': 312,\n",
       " 'himself': 313,\n",
       " 'seeing': 314,\n",
       " 'john': 315,\n",
       " 'night': 316,\n",
       " 'black': 317,\n",
       " 'version': 318,\n",
       " 'shot': 319,\n",
       " 'excellent': 320,\n",
       " 'idea': 321,\n",
       " 'house': 322,\n",
       " 'mind': 323,\n",
       " 'star': 324,\n",
       " 'wife': 325,\n",
       " 'fan': 326,\n",
       " 'death': 327,\n",
       " 'used': 328,\n",
       " 'else': 329,\n",
       " 'simply': 330,\n",
       " 'nice': 331,\n",
       " 'budget': 332,\n",
       " 'poor': 333,\n",
       " 'short': 334,\n",
       " 'completely': 335,\n",
       " 'second': 336,\n",
       " \"you're\": 337,\n",
       " '3': 338,\n",
       " 'read': 339,\n",
       " 'less': 340,\n",
       " 'along': 341,\n",
       " 'top': 342,\n",
       " 'help': 343,\n",
       " 'home': 344,\n",
       " 'men': 345,\n",
       " 'either': 346,\n",
       " 'line': 347,\n",
       " 'boring': 348,\n",
       " 'dead': 349,\n",
       " 'friends': 350,\n",
       " 'kids': 351,\n",
       " 'try': 352,\n",
       " 'production': 353,\n",
       " 'enjoy': 354,\n",
       " 'camera': 355,\n",
       " 'use': 356,\n",
       " 'wrong': 357,\n",
       " 'given': 358,\n",
       " 'low': 359,\n",
       " 'classic': 360,\n",
       " 'father': 361,\n",
       " 'need': 362,\n",
       " 'full': 363,\n",
       " 'stupid': 364,\n",
       " 'next': 365,\n",
       " 'until': 366,\n",
       " 'performances': 367,\n",
       " 'school': 368,\n",
       " 'hollywood': 369,\n",
       " 'rest': 370,\n",
       " 'truly': 371,\n",
       " 'awful': 372,\n",
       " 'video': 373,\n",
       " 'couple': 374,\n",
       " 'start': 375,\n",
       " 'sex': 376,\n",
       " 'recommend': 377,\n",
       " 'women': 378,\n",
       " 'let': 379,\n",
       " 'tell': 380,\n",
       " 'terrible': 381,\n",
       " 'remember': 382,\n",
       " 'mean': 383,\n",
       " 'came': 384,\n",
       " 'getting': 385,\n",
       " 'understand': 386,\n",
       " 'perhaps': 387,\n",
       " 'moments': 388,\n",
       " 'name': 389,\n",
       " 'keep': 390,\n",
       " 'face': 391,\n",
       " 'itself': 392,\n",
       " 'wonderful': 393,\n",
       " 'playing': 394,\n",
       " 'human': 395,\n",
       " 'style': 396,\n",
       " 'small': 397,\n",
       " 'episode': 398,\n",
       " 'perfect': 399,\n",
       " 'others': 400,\n",
       " 'person': 401,\n",
       " 'doing': 402,\n",
       " 'often': 403,\n",
       " 'early': 404,\n",
       " 'stars': 405,\n",
       " 'definitely': 406,\n",
       " 'written': 407,\n",
       " 'head': 408,\n",
       " 'lines': 409,\n",
       " 'dialogue': 410,\n",
       " 'gives': 411,\n",
       " 'piece': 412,\n",
       " \"couldn't\": 413,\n",
       " 'went': 414,\n",
       " 'finally': 415,\n",
       " 'mother': 416,\n",
       " 'case': 417,\n",
       " 'title': 418,\n",
       " 'absolutely': 419,\n",
       " 'live': 420,\n",
       " 'boy': 421,\n",
       " 'yes': 422,\n",
       " 'laugh': 423,\n",
       " 'certainly': 424,\n",
       " 'liked': 425,\n",
       " 'become': 426,\n",
       " 'entertaining': 427,\n",
       " 'worse': 428,\n",
       " 'oh': 429,\n",
       " 'sort': 430,\n",
       " 'loved': 431,\n",
       " 'lost': 432,\n",
       " 'hope': 433,\n",
       " 'called': 434,\n",
       " 'picture': 435,\n",
       " 'felt': 436,\n",
       " 'overall': 437,\n",
       " 'entire': 438,\n",
       " 'mr': 439,\n",
       " 'several': 440,\n",
       " 'based': 441,\n",
       " 'supposed': 442,\n",
       " 'cinema': 443,\n",
       " 'friend': 444,\n",
       " 'guys': 445,\n",
       " 'sound': 446,\n",
       " '5': 447,\n",
       " 'problem': 448,\n",
       " 'drama': 449,\n",
       " 'against': 450,\n",
       " 'waste': 451,\n",
       " 'white': 452,\n",
       " 'beginning': 453,\n",
       " '4': 454,\n",
       " 'fans': 455,\n",
       " 'totally': 456,\n",
       " 'dark': 457,\n",
       " 'care': 458,\n",
       " 'direction': 459,\n",
       " 'humor': 460,\n",
       " 'wanted': 461,\n",
       " \"she's\": 462,\n",
       " 'seemed': 463,\n",
       " 'under': 464,\n",
       " 'game': 465,\n",
       " 'children': 466,\n",
       " 'despite': 467,\n",
       " 'lives': 468,\n",
       " 'lead': 469,\n",
       " 'guess': 470,\n",
       " 'example': 471,\n",
       " 'already': 472,\n",
       " 'final': 473,\n",
       " 'throughout': 474,\n",
       " \"you'll\": 475,\n",
       " 'evil': 476,\n",
       " 'turn': 477,\n",
       " 'becomes': 478,\n",
       " 'unfortunately': 479,\n",
       " 'able': 480,\n",
       " 'quality': 481,\n",
       " \"i'd\": 482,\n",
       " 'days': 483,\n",
       " 'history': 484,\n",
       " 'fine': 485,\n",
       " 'side': 486,\n",
       " 'wants': 487,\n",
       " 'heart': 488,\n",
       " 'horrible': 489,\n",
       " 'writing': 490,\n",
       " 'amazing': 491,\n",
       " 'b': 492,\n",
       " 'flick': 493,\n",
       " 'killer': 494,\n",
       " 'run': 495,\n",
       " 'son': 496,\n",
       " 'â\\x96': 497,\n",
       " 'michael': 498,\n",
       " 'works': 499,\n",
       " 'close': 500,\n",
       " \"they're\": 501,\n",
       " 'act': 502,\n",
       " 'art': 503,\n",
       " 'matter': 504,\n",
       " 'kill': 505,\n",
       " 'etc': 506,\n",
       " 'tries': 507,\n",
       " \"won't\": 508,\n",
       " 'past': 509,\n",
       " 'town': 510,\n",
       " 'turns': 511,\n",
       " 'enjoyed': 512,\n",
       " 'brilliant': 513,\n",
       " 'gave': 514,\n",
       " 'behind': 515,\n",
       " 'parts': 516,\n",
       " 'stuff': 517,\n",
       " 'genre': 518,\n",
       " 'eyes': 519,\n",
       " 'car': 520,\n",
       " 'favorite': 521,\n",
       " 'directed': 522,\n",
       " 'late': 523,\n",
       " 'hand': 524,\n",
       " 'expect': 525,\n",
       " 'soon': 526,\n",
       " 'hour': 527,\n",
       " 'obviously': 528,\n",
       " 'themselves': 529,\n",
       " 'sometimes': 530,\n",
       " 'killed': 531,\n",
       " 'actress': 532,\n",
       " 'thinking': 533,\n",
       " 'child': 534,\n",
       " 'girls': 535,\n",
       " 'viewer': 536,\n",
       " 'starts': 537,\n",
       " 'city': 538,\n",
       " 'myself': 539,\n",
       " 'decent': 540,\n",
       " 'highly': 541,\n",
       " 'stop': 542,\n",
       " 'type': 543,\n",
       " 'self': 544,\n",
       " 'god': 545,\n",
       " 'says': 546,\n",
       " 'group': 547,\n",
       " 'anyway': 548,\n",
       " 'voice': 549,\n",
       " 'took': 550,\n",
       " 'known': 551,\n",
       " 'blood': 552,\n",
       " 'kid': 553,\n",
       " 'heard': 554,\n",
       " 'happens': 555,\n",
       " 'except': 556,\n",
       " 'fight': 557,\n",
       " 'feeling': 558,\n",
       " 'experience': 559,\n",
       " 'coming': 560,\n",
       " 'slow': 561,\n",
       " 'daughter': 562,\n",
       " 'writer': 563,\n",
       " 'stories': 564,\n",
       " 'moment': 565,\n",
       " 'leave': 566,\n",
       " 'told': 567,\n",
       " 'extremely': 568,\n",
       " 'score': 569,\n",
       " 'violence': 570,\n",
       " 'police': 571,\n",
       " 'involved': 572,\n",
       " 'strong': 573,\n",
       " 'chance': 574,\n",
       " 'lack': 575,\n",
       " 'cannot': 576,\n",
       " 'hit': 577,\n",
       " 'roles': 578,\n",
       " 'hilarious': 579,\n",
       " 's': 580,\n",
       " 'wonder': 581,\n",
       " 'happen': 582,\n",
       " 'particularly': 583,\n",
       " 'ok': 584,\n",
       " 'including': 585,\n",
       " 'living': 586,\n",
       " 'save': 587,\n",
       " 'looked': 588,\n",
       " \"wouldn't\": 589,\n",
       " 'crap': 590,\n",
       " 'please': 591,\n",
       " 'simple': 592,\n",
       " 'murder': 593,\n",
       " 'cool': 594,\n",
       " 'obvious': 595,\n",
       " 'happened': 596,\n",
       " 'complete': 597,\n",
       " 'cut': 598,\n",
       " 'age': 599,\n",
       " 'serious': 600,\n",
       " 'gore': 601,\n",
       " 'attempt': 602,\n",
       " 'hell': 603,\n",
       " 'ago': 604,\n",
       " 'song': 605,\n",
       " 'shown': 606,\n",
       " 'taken': 607,\n",
       " 'english': 608,\n",
       " 'james': 609,\n",
       " 'robert': 610,\n",
       " 'david': 611,\n",
       " 'seriously': 612,\n",
       " 'released': 613,\n",
       " 'reality': 614,\n",
       " 'opening': 615,\n",
       " 'jokes': 616,\n",
       " 'interest': 617,\n",
       " 'across': 618,\n",
       " 'none': 619,\n",
       " 'hero': 620,\n",
       " 'today': 621,\n",
       " 'possible': 622,\n",
       " 'exactly': 623,\n",
       " 'alone': 624,\n",
       " 'sad': 625,\n",
       " 'brother': 626,\n",
       " 'number': 627,\n",
       " 'saying': 628,\n",
       " 'career': 629,\n",
       " \"film's\": 630,\n",
       " 'usually': 631,\n",
       " 'hours': 632,\n",
       " 'cinematography': 633,\n",
       " 'talent': 634,\n",
       " 'view': 635,\n",
       " 'yourself': 636,\n",
       " 'annoying': 637,\n",
       " 'running': 638,\n",
       " 'relationship': 639,\n",
       " 'documentary': 640,\n",
       " 'wish': 641,\n",
       " 'order': 642,\n",
       " 'huge': 643,\n",
       " 'whose': 644,\n",
       " 'shots': 645,\n",
       " 'ridiculous': 646,\n",
       " 'taking': 647,\n",
       " 'important': 648,\n",
       " 'light': 649,\n",
       " 'body': 650,\n",
       " 'middle': 651,\n",
       " 'level': 652,\n",
       " 'ends': 653,\n",
       " 'female': 654,\n",
       " 'started': 655,\n",
       " 'call': 656,\n",
       " \"i'll\": 657,\n",
       " 'husband': 658,\n",
       " 'four': 659,\n",
       " 'power': 660,\n",
       " 'major': 661,\n",
       " 'word': 662,\n",
       " 'turned': 663,\n",
       " 'opinion': 664,\n",
       " 'change': 665,\n",
       " 'mostly': 666,\n",
       " 'usual': 667,\n",
       " 'scary': 668,\n",
       " 'silly': 669,\n",
       " 'rating': 670,\n",
       " 'beyond': 671,\n",
       " 'somewhat': 672,\n",
       " 'ones': 673,\n",
       " 'happy': 674,\n",
       " 'words': 675,\n",
       " 'room': 676,\n",
       " 'knew': 677,\n",
       " 'knows': 678,\n",
       " 'country': 679,\n",
       " 'disappointed': 680,\n",
       " 'talking': 681,\n",
       " 'novel': 682,\n",
       " 'apparently': 683,\n",
       " 'non': 684,\n",
       " 'strange': 685,\n",
       " 'attention': 686,\n",
       " 'upon': 687,\n",
       " 'finds': 688,\n",
       " 'single': 689,\n",
       " 'basically': 690,\n",
       " 'cheap': 691,\n",
       " 'modern': 692,\n",
       " 'due': 693,\n",
       " 'jack': 694,\n",
       " 'television': 695,\n",
       " 'musical': 696,\n",
       " 'problems': 697,\n",
       " 'miss': 698,\n",
       " 'episodes': 699,\n",
       " 'clearly': 700,\n",
       " 'local': 701,\n",
       " '7': 702,\n",
       " 'british': 703,\n",
       " 'thriller': 704,\n",
       " 'talk': 705,\n",
       " 'events': 706,\n",
       " 'five': 707,\n",
       " 'sequence': 708,\n",
       " \"aren't\": 709,\n",
       " 'class': 710,\n",
       " 'french': 711,\n",
       " 'moving': 712,\n",
       " 'ten': 713,\n",
       " 'fast': 714,\n",
       " 'review': 715,\n",
       " 'earth': 716,\n",
       " 'tells': 717,\n",
       " 'predictable': 718,\n",
       " 'team': 719,\n",
       " 'songs': 720,\n",
       " 'comic': 721,\n",
       " 'straight': 722,\n",
       " '8': 723,\n",
       " 'whether': 724,\n",
       " 'die': 725,\n",
       " 'add': 726,\n",
       " 'dialog': 727,\n",
       " 'entertainment': 728,\n",
       " 'above': 729,\n",
       " 'sets': 730,\n",
       " 'future': 731,\n",
       " 'enjoyable': 732,\n",
       " 'appears': 733,\n",
       " 'near': 734,\n",
       " 'space': 735,\n",
       " 'easily': 736,\n",
       " 'hate': 737,\n",
       " 'soundtrack': 738,\n",
       " 'bring': 739,\n",
       " 'giving': 740,\n",
       " 'lots': 741,\n",
       " 'similar': 742,\n",
       " 'romantic': 743,\n",
       " 'george': 744,\n",
       " 'supporting': 745,\n",
       " 'release': 746,\n",
       " 'mention': 747,\n",
       " 'within': 748,\n",
       " 'filmed': 749,\n",
       " 'message': 750,\n",
       " 'sequel': 751,\n",
       " 'clear': 752,\n",
       " 'falls': 753,\n",
       " 'needs': 754,\n",
       " \"haven't\": 755,\n",
       " 'dull': 756,\n",
       " 'suspense': 757,\n",
       " 'bunch': 758,\n",
       " 'eye': 759,\n",
       " 'surprised': 760,\n",
       " 'showing': 761,\n",
       " 'tried': 762,\n",
       " 'sorry': 763,\n",
       " 'certain': 764,\n",
       " 'working': 765,\n",
       " 'easy': 766,\n",
       " 'ways': 767,\n",
       " 'theme': 768,\n",
       " 'theater': 769,\n",
       " 'named': 770,\n",
       " 'among': 771,\n",
       " \"what's\": 772,\n",
       " 'storyline': 773,\n",
       " 'monster': 774,\n",
       " 'king': 775,\n",
       " 'stay': 776,\n",
       " 'effort': 777,\n",
       " 'fall': 778,\n",
       " 'stand': 779,\n",
       " 'minute': 780,\n",
       " 'gone': 781,\n",
       " 'rock': 782,\n",
       " 'using': 783,\n",
       " '9': 784,\n",
       " 'feature': 785,\n",
       " 'comments': 786,\n",
       " 'buy': 787,\n",
       " \"'\": 788,\n",
       " 'typical': 789,\n",
       " 't': 790,\n",
       " 'editing': 791,\n",
       " 'sister': 792,\n",
       " 'avoid': 793,\n",
       " 'tale': 794,\n",
       " 'mystery': 795,\n",
       " 'deal': 796,\n",
       " 'dr': 797,\n",
       " 'doubt': 798,\n",
       " 'fantastic': 799,\n",
       " 'kept': 800,\n",
       " 'nearly': 801,\n",
       " 'feels': 802,\n",
       " 'okay': 803,\n",
       " 'subject': 804,\n",
       " 'viewing': 805,\n",
       " 'elements': 806,\n",
       " 'oscar': 807,\n",
       " 'check': 808,\n",
       " 'realistic': 809,\n",
       " 'points': 810,\n",
       " 'greatest': 811,\n",
       " 'means': 812,\n",
       " 'herself': 813,\n",
       " 'parents': 814,\n",
       " 'famous': 815,\n",
       " 'imagine': 816,\n",
       " 'rent': 817,\n",
       " 'viewers': 818,\n",
       " 'richard': 819,\n",
       " 'crime': 820,\n",
       " 'form': 821,\n",
       " 'peter': 822,\n",
       " 'actual': 823,\n",
       " 'lady': 824,\n",
       " 'general': 825,\n",
       " 'dog': 826,\n",
       " 'follow': 827,\n",
       " 'believable': 828,\n",
       " 'period': 829,\n",
       " 'red': 830,\n",
       " 'move': 831,\n",
       " 'brought': 832,\n",
       " 'material': 833,\n",
       " 'forget': 834,\n",
       " 'somehow': 835,\n",
       " 'begins': 836,\n",
       " 're': 837,\n",
       " 'reviews': 838,\n",
       " 'animation': 839,\n",
       " 'paul': 840,\n",
       " \"you've\": 841,\n",
       " 'leads': 842,\n",
       " 'weak': 843,\n",
       " 'figure': 844,\n",
       " 'surprise': 845,\n",
       " 'hear': 846,\n",
       " 'sit': 847,\n",
       " 'average': 848,\n",
       " 'open': 849,\n",
       " 'sequences': 850,\n",
       " 'atmosphere': 851,\n",
       " 'killing': 852,\n",
       " 'eventually': 853,\n",
       " 'tom': 854,\n",
       " 'learn': 855,\n",
       " 'premise': 856,\n",
       " '20': 857,\n",
       " 'wait': 858,\n",
       " 'sci': 859,\n",
       " 'deep': 860,\n",
       " 'fi': 861,\n",
       " 'expected': 862,\n",
       " 'whatever': 863,\n",
       " 'indeed': 864,\n",
       " 'particular': 865,\n",
       " 'poorly': 866,\n",
       " 'note': 867,\n",
       " 'lame': 868,\n",
       " 'dance': 869,\n",
       " 'imdb': 870,\n",
       " 'situation': 871,\n",
       " 'shame': 872,\n",
       " 'third': 873,\n",
       " 'york': 874,\n",
       " 'box': 875,\n",
       " 'truth': 876,\n",
       " 'decided': 877,\n",
       " 'free': 878,\n",
       " 'hot': 879,\n",
       " \"who's\": 880,\n",
       " 'difficult': 881,\n",
       " 'needed': 882,\n",
       " 'season': 883,\n",
       " 'acted': 884,\n",
       " 'leaves': 885,\n",
       " 'unless': 886,\n",
       " 'possibly': 887,\n",
       " 'emotional': 888,\n",
       " 'romance': 889,\n",
       " 'gay': 890,\n",
       " 'sexual': 891,\n",
       " 'boys': 892,\n",
       " 'footage': 893,\n",
       " 'write': 894,\n",
       " 'western': 895,\n",
       " 'forced': 896,\n",
       " 'credits': 897,\n",
       " 'reading': 898,\n",
       " 'memorable': 899,\n",
       " 'became': 900,\n",
       " 'doctor': 901,\n",
       " 'otherwise': 902,\n",
       " 'crew': 903,\n",
       " 'begin': 904,\n",
       " 'air': 905,\n",
       " 'de': 906,\n",
       " 'question': 907,\n",
       " 'society': 908,\n",
       " 'meet': 909,\n",
       " 'male': 910,\n",
       " 'meets': 911,\n",
       " \"let's\": 912,\n",
       " 'plus': 913,\n",
       " 'cheesy': 914,\n",
       " 'hands': 915,\n",
       " 'superb': 916,\n",
       " 'screenplay': 917,\n",
       " 'interested': 918,\n",
       " 'beauty': 919,\n",
       " 'street': 920,\n",
       " 'features': 921,\n",
       " 'masterpiece': 922,\n",
       " 'perfectly': 923,\n",
       " 'whom': 924,\n",
       " 'laughs': 925,\n",
       " 'nature': 926,\n",
       " 'stage': 927,\n",
       " 'effect': 928,\n",
       " 'forward': 929,\n",
       " 'comment': 930,\n",
       " 'nor': 931,\n",
       " 'previous': 932,\n",
       " 'badly': 933,\n",
       " 'sounds': 934,\n",
       " 'e': 935,\n",
       " 'japanese': 936,\n",
       " 'weird': 937,\n",
       " 'island': 938,\n",
       " 'personal': 939,\n",
       " 'inside': 940,\n",
       " 'quickly': 941,\n",
       " 'total': 942,\n",
       " 'keeps': 943,\n",
       " 'towards': 944,\n",
       " 'result': 945,\n",
       " 'america': 946,\n",
       " 'battle': 947,\n",
       " 'crazy': 948,\n",
       " 'worked': 949,\n",
       " 'setting': 950,\n",
       " 'incredibly': 951,\n",
       " 'background': 952,\n",
       " 'earlier': 953,\n",
       " 'mess': 954,\n",
       " 'cop': 955,\n",
       " 'writers': 956,\n",
       " 'fire': 957,\n",
       " 'copy': 958,\n",
       " 'dumb': 959,\n",
       " 'unique': 960,\n",
       " 'realize': 961,\n",
       " 'powerful': 962,\n",
       " 'lee': 963,\n",
       " 'mark': 964,\n",
       " 'business': 965,\n",
       " 'rate': 966,\n",
       " 'dramatic': 967,\n",
       " 'older': 968,\n",
       " 'pay': 969,\n",
       " 'following': 970,\n",
       " 'directors': 971,\n",
       " 'girlfriend': 972,\n",
       " 'joke': 973,\n",
       " 'plenty': 974,\n",
       " 'directing': 975,\n",
       " 'various': 976,\n",
       " 'creepy': 977,\n",
       " 'baby': 978,\n",
       " 'development': 979,\n",
       " 'appear': 980,\n",
       " 'brings': 981,\n",
       " 'front': 982,\n",
       " 'ask': 983,\n",
       " 'dream': 984,\n",
       " 'water': 985,\n",
       " 'rich': 986,\n",
       " 'admit': 987,\n",
       " 'bill': 988,\n",
       " 'apart': 989,\n",
       " 'joe': 990,\n",
       " 'fairly': 991,\n",
       " 'political': 992,\n",
       " 'leading': 993,\n",
       " 'reasons': 994,\n",
       " 'portrayed': 995,\n",
       " 'spent': 996,\n",
       " 'telling': 997,\n",
       " 'cover': 998,\n",
       " 'outside': 999,\n",
       " 'fighting': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_tokens = tokenizer.texts_to_sequences(X_train_text)\n",
    "#list of tokens within a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_tokens = tokenizer.texts_to_sequences(X_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school life, such as \"Teachers\". My 35 years in the teaching profession lead me to believe that Bromwell High\\'s satire is much closer to reality than is \"Teachers\". The scramble to survive financially, the insightful students who can see right through their pathetic teachers\\' pomp, the pettiness of the whole situation, all remind me of the schools I knew and their students. When I saw the episode in which a student repeatedly tried to burn down the school, I immediately recalled ......... at .......... High. A classic line: INSPECTOR: I\\'m here to sack one of your teachers. STUDENT: Welcome to Bromwell High. I expect that many adults of my age think that Bromwell High is far fetched. What a pity that it isn\\'t!'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[299,\n",
       "  6,\n",
       "  3,\n",
       "  1059,\n",
       "  202,\n",
       "  9,\n",
       "  2119,\n",
       "  30,\n",
       "  1,\n",
       "  167,\n",
       "  55,\n",
       "  14,\n",
       "  47,\n",
       "  79,\n",
       "  6274,\n",
       "  42,\n",
       "  368,\n",
       "  114,\n",
       "  138,\n",
       "  14,\n",
       "  5103,\n",
       "  56,\n",
       "  4515,\n",
       "  153,\n",
       "  8,\n",
       "  1,\n",
       "  4233,\n",
       "  5799,\n",
       "  469,\n",
       "  68,\n",
       "  5,\n",
       "  262,\n",
       "  12,\n",
       "  2072,\n",
       "  6,\n",
       "  72,\n",
       "  2556,\n",
       "  5,\n",
       "  614,\n",
       "  71,\n",
       "  6,\n",
       "  5103,\n",
       "  1,\n",
       "  5,\n",
       "  1897,\n",
       "  1,\n",
       "  5540,\n",
       "  1469,\n",
       "  35,\n",
       "  67,\n",
       "  63,\n",
       "  203,\n",
       "  140,\n",
       "  65,\n",
       "  1151,\n",
       "  1,\n",
       "  4,\n",
       "  1,\n",
       "  223,\n",
       "  871,\n",
       "  29,\n",
       "  3195,\n",
       "  68,\n",
       "  4,\n",
       "  1,\n",
       "  5510,\n",
       "  10,\n",
       "  677,\n",
       "  2,\n",
       "  65,\n",
       "  1469,\n",
       "  50,\n",
       "  10,\n",
       "  210,\n",
       "  1,\n",
       "  398,\n",
       "  8,\n",
       "  60,\n",
       "  3,\n",
       "  1425,\n",
       "  3345,\n",
       "  762,\n",
       "  5,\n",
       "  3491,\n",
       "  175,\n",
       "  1,\n",
       "  368,\n",
       "  10,\n",
       "  1220,\n",
       "  30,\n",
       "  299,\n",
       "  3,\n",
       "  360,\n",
       "  347,\n",
       "  3471,\n",
       "  145,\n",
       "  133,\n",
       "  5,\n",
       "  8306,\n",
       "  27,\n",
       "  4,\n",
       "  125,\n",
       "  5103,\n",
       "  1425,\n",
       "  2563,\n",
       "  5,\n",
       "  299,\n",
       "  10,\n",
       "  525,\n",
       "  12,\n",
       "  106,\n",
       "  1540,\n",
       "  4,\n",
       "  56,\n",
       "  599,\n",
       "  101,\n",
       "  12,\n",
       "  299,\n",
       "  6,\n",
       "  225,\n",
       "  3994,\n",
       "  48,\n",
       "  3,\n",
       "  2244,\n",
       "  12,\n",
       "  9,\n",
       "  213],\n",
       " [38,\n",
       "  14,\n",
       "  744,\n",
       "  3506,\n",
       "  45,\n",
       "  75,\n",
       "  32,\n",
       "  1771,\n",
       "  15,\n",
       "  153,\n",
       "  18,\n",
       "  110,\n",
       "  3,\n",
       "  1344,\n",
       "  5,\n",
       "  343,\n",
       "  143,\n",
       "  20,\n",
       "  1,\n",
       "  920,\n",
       "  12,\n",
       "  70,\n",
       "  281,\n",
       "  1228,\n",
       "  395,\n",
       "  35,\n",
       "  115,\n",
       "  267,\n",
       "  36,\n",
       "  166,\n",
       "  5,\n",
       "  368,\n",
       "  158,\n",
       "  38,\n",
       "  2058,\n",
       "  15,\n",
       "  1,\n",
       "  504,\n",
       "  88,\n",
       "  83,\n",
       "  101,\n",
       "  4,\n",
       "  1,\n",
       "  4339,\n",
       "  14,\n",
       "  39,\n",
       "  3,\n",
       "  432,\n",
       "  1148,\n",
       "  136,\n",
       "  8697,\n",
       "  42,\n",
       "  177,\n",
       "  138,\n",
       "  14,\n",
       "  2791,\n",
       "  1,\n",
       "  295,\n",
       "  20,\n",
       "  5276,\n",
       "  351,\n",
       "  5,\n",
       "  3029,\n",
       "  2310,\n",
       "  1,\n",
       "  38,\n",
       "  8697,\n",
       "  43,\n",
       "  3611,\n",
       "  26,\n",
       "  365,\n",
       "  5,\n",
       "  127,\n",
       "  53,\n",
       "  20,\n",
       "  1,\n",
       "  2032,\n",
       "  7,\n",
       "  7,\n",
       "  18,\n",
       "  48,\n",
       "  43,\n",
       "  22,\n",
       "  70,\n",
       "  358,\n",
       "  3,\n",
       "  2343,\n",
       "  5,\n",
       "  420,\n",
       "  20,\n",
       "  1,\n",
       "  2032,\n",
       "  15,\n",
       "  3,\n",
       "  3346,\n",
       "  208,\n",
       "  1,\n",
       "  22,\n",
       "  281,\n",
       "  66,\n",
       "  36,\n",
       "  3,\n",
       "  344,\n",
       "  1,\n",
       "  728,\n",
       "  730,\n",
       "  3,\n",
       "  3864,\n",
       "  1320,\n",
       "  20,\n",
       "  1,\n",
       "  1543,\n",
       "  3,\n",
       "  1293,\n",
       "  2,\n",
       "  267,\n",
       "  22,\n",
       "  281,\n",
       "  2734,\n",
       "  5,\n",
       "  63,\n",
       "  48,\n",
       "  44,\n",
       "  37,\n",
       "  5,\n",
       "  26,\n",
       "  4339,\n",
       "  12,\n",
       "  6,\n",
       "  2079,\n",
       "  7,\n",
       "  7,\n",
       "  3425,\n",
       "  2891,\n",
       "  35,\n",
       "  4446,\n",
       "  35,\n",
       "  405,\n",
       "  14,\n",
       "  297,\n",
       "  3,\n",
       "  986,\n",
       "  128,\n",
       "  35,\n",
       "  45,\n",
       "  267,\n",
       "  8,\n",
       "  1,\n",
       "  181,\n",
       "  366,\n",
       "  6951,\n",
       "  5,\n",
       "  94,\n",
       "  3,\n",
       "  2343,\n",
       "  16,\n",
       "  3,\n",
       "  7017,\n",
       "  3090,\n",
       "  5,\n",
       "  63,\n",
       "  43,\n",
       "  28,\n",
       "  67,\n",
       "  420,\n",
       "  8,\n",
       "  1,\n",
       "  2032,\n",
       "  15,\n",
       "  3082,\n",
       "  483,\n",
       "  208,\n",
       "  1,\n",
       "  43,\n",
       "  2802,\n",
       "  28,\n",
       "  67,\n",
       "  77,\n",
       "  48,\n",
       "  28,\n",
       "  487,\n",
       "  16,\n",
       "  3,\n",
       "  731,\n",
       "  1146,\n",
       "  4,\n",
       "  232,\n",
       "  51,\n",
       "  4161,\n",
       "  1,\n",
       "  20,\n",
       "  117,\n",
       "  6,\n",
       "  1334,\n",
       "  20,\n",
       "  1,\n",
       "  920,\n",
       "  16,\n",
       "  3,\n",
       "  20,\n",
       "  24,\n",
       "  4086,\n",
       "  5,\n",
       "  24,\n",
       "  170,\n",
       "  831,\n",
       "  117,\n",
       "  28,\n",
       "  185,\n",
       "  1562,\n",
       "  122,\n",
       "  1,\n",
       "  7951,\n",
       "  237,\n",
       "  358,\n",
       "  1,\n",
       "  31,\n",
       "  3,\n",
       "  100,\n",
       "  44,\n",
       "  407,\n",
       "  20,\n",
       "  24,\n",
       "  9597,\n",
       "  117,\n",
       "  911,\n",
       "  79,\n",
       "  102,\n",
       "  585,\n",
       "  3,\n",
       "  257,\n",
       "  31,\n",
       "  1,\n",
       "  389,\n",
       "  4,\n",
       "  5176,\n",
       "  2137,\n",
       "  4636,\n",
       "  32,\n",
       "  1222,\n",
       "  3303,\n",
       "  35,\n",
       "  189,\n",
       "  4287,\n",
       "  159,\n",
       "  2320,\n",
       "  40,\n",
       "  344,\n",
       "  2,\n",
       "  40,\n",
       "  8527,\n",
       "  6229,\n",
       "  1955,\n",
       "  4910,\n",
       "  2,\n",
       "  7720,\n",
       "  2618,\n",
       "  35,\n",
       "  23,\n",
       "  472,\n",
       "  328,\n",
       "  5,\n",
       "  1,\n",
       "  2032,\n",
       "  501,\n",
       "  4392,\n",
       "  213,\n",
       "  237,\n",
       "  21,\n",
       "  328,\n",
       "  5,\n",
       "  4805,\n",
       "  6768,\n",
       "  37,\n",
       "  28,\n",
       "  281,\n",
       "  115,\n",
       "  50,\n",
       "  109,\n",
       "  986,\n",
       "  117,\n",
       "  44,\n",
       "  557,\n",
       "  38,\n",
       "  2574,\n",
       "  505,\n",
       "  38,\n",
       "  26,\n",
       "  531,\n",
       "  7,\n",
       "  7,\n",
       "  136,\n",
       "  1,\n",
       "  112,\n",
       "  1906,\n",
       "  201,\n",
       "  5176,\n",
       "  2,\n",
       "  292,\n",
       "  1731,\n",
       "  5,\n",
       "  111,\n",
       "  10,\n",
       "  255,\n",
       "  114,\n",
       "  4541,\n",
       "  5,\n",
       "  26,\n",
       "  27,\n",
       "  4,\n",
       "  3425,\n",
       "  104,\n",
       "  117,\n",
       "  2557,\n",
       "  5,\n",
       "  109,\n",
       "  3,\n",
       "  202,\n",
       "  9,\n",
       "  276,\n",
       "  3,\n",
       "  4317,\n",
       "  486,\n",
       "  1107,\n",
       "  5,\n",
       "  24,\n",
       "  2347,\n",
       "  158,\n",
       "  138,\n",
       "  14,\n",
       "  8161,\n",
       "  186,\n",
       "  3889,\n",
       "  38,\n",
       "  15,\n",
       "  1,\n",
       "  504,\n",
       "  5,\n",
       "  119,\n",
       "  48,\n",
       "  44,\n",
       "  37,\n",
       "  263,\n",
       "  137,\n",
       "  4737,\n",
       "  159,\n",
       "  2320,\n",
       "  9,\n",
       "  1,\n",
       "  365,\n",
       "  254,\n",
       "  38,\n",
       "  20,\n",
       "  1,\n",
       "  79,\n",
       "  524,\n",
       "  232,\n",
       "  3,\n",
       "  364,\n",
       "  2343,\n",
       "  37,\n",
       "  29,\n",
       "  986,\n",
       "  83,\n",
       "  77,\n",
       "  50,\n",
       "  33,\n",
       "  89,\n",
       "  118,\n",
       "  48,\n",
       "  5,\n",
       "  77,\n",
       "  16,\n",
       "  65,\n",
       "  290,\n",
       "  273,\n",
       "  33,\n",
       "  142,\n",
       "  197,\n",
       "  9,\n",
       "  5,\n",
       "  1,\n",
       "  4339,\n",
       "  298,\n",
       "  4,\n",
       "  783,\n",
       "  9,\n",
       "  37,\n",
       "  290,\n",
       "  7,\n",
       "  7,\n",
       "  38,\n",
       "  273,\n",
       "  11,\n",
       "  19,\n",
       "  80,\n",
       "  5541,\n",
       "  22,\n",
       "  5,\n",
       "  343,\n",
       "  400]]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tokens[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([299, 6, 3, 1059, 202, 9, 2119, 30, 1, 167, 55, 14, 47, 79, 6274, 42, 368, 114, 138, 14, 5103, 56, 4515, 153, 8, 1, 4233, 5799, 469, 68, 5, 262, 12, 2072, 6, 72, 2556, 5, 614, 71, 6, 5103, 1, 5, 1897, 1, 5540, 1469, 35, 67, 63, 203, 140, 65, 1151, 1, 4, 1, 223, 871, 29, 3195, 68, 4, 1, 5510, 10, 677, 2, 65, 1469, 50, 10, 210, 1, 398, 8, 60, 3, 1425, 3345, 762, 5, 3491, 175, 1, 368, 10, 1220, 30, 299, 3, 360, 347, 3471, 145, 133, 5, 8306, 27, 4, 125, 5103, 1425, 2563, 5, 299, 10, 525, 12, 106, 1540, 4, 56, 599, 101, 12, 299, 6, 225, 3994, 48, 3, 2244, 12, 9, 213]),\n",
       "       list([38, 14, 744, 3506, 45, 75, 32, 1771, 15, 153, 18, 110, 3, 1344, 5, 343, 143, 20, 1, 920, 12, 70, 281, 1228, 395, 35, 115, 267, 36, 166, 5, 368, 158, 38, 2058, 15, 1, 504, 88, 83, 101, 4, 1, 4339, 14, 39, 3, 432, 1148, 136, 8697, 42, 177, 138, 14, 2791, 1, 295, 20, 5276, 351, 5, 3029, 2310, 1, 38, 8697, 43, 3611, 26, 365, 5, 127, 53, 20, 1, 2032, 7, 7, 18, 48, 43, 22, 70, 358, 3, 2343, 5, 420, 20, 1, 2032, 15, 3, 3346, 208, 1, 22, 281, 66, 36, 3, 344, 1, 728, 730, 3, 3864, 1320, 20, 1, 1543, 3, 1293, 2, 267, 22, 281, 2734, 5, 63, 48, 44, 37, 5, 26, 4339, 12, 6, 2079, 7, 7, 3425, 2891, 35, 4446, 35, 405, 14, 297, 3, 986, 128, 35, 45, 267, 8, 1, 181, 366, 6951, 5, 94, 3, 2343, 16, 3, 7017, 3090, 5, 63, 43, 28, 67, 420, 8, 1, 2032, 15, 3082, 483, 208, 1, 43, 2802, 28, 67, 77, 48, 28, 487, 16, 3, 731, 1146, 4, 232, 51, 4161, 1, 20, 117, 6, 1334, 20, 1, 920, 16, 3, 20, 24, 4086, 5, 24, 170, 831, 117, 28, 185, 1562, 122, 1, 7951, 237, 358, 1, 31, 3, 100, 44, 407, 20, 24, 9597, 117, 911, 79, 102, 585, 3, 257, 31, 1, 389, 4, 5176, 2137, 4636, 32, 1222, 3303, 35, 189, 4287, 159, 2320, 40, 344, 2, 40, 8527, 6229, 1955, 4910, 2, 7720, 2618, 35, 23, 472, 328, 5, 1, 2032, 501, 4392, 213, 237, 21, 328, 5, 4805, 6768, 37, 28, 281, 115, 50, 109, 986, 117, 44, 557, 38, 2574, 505, 38, 26, 531, 7, 7, 136, 1, 112, 1906, 201, 5176, 2, 292, 1731, 5, 111, 10, 255, 114, 4541, 5, 26, 27, 4, 3425, 104, 117, 2557, 5, 109, 3, 202, 9, 276, 3, 4317, 486, 1107, 5, 24, 2347, 158, 138, 14, 8161, 186, 3889, 38, 15, 1, 504, 5, 119, 48, 44, 37, 263, 137, 4737, 159, 2320, 9, 1, 365, 254, 38, 20, 1, 79, 524, 232, 3, 364, 2343, 37, 29, 986, 83, 77, 50, 33, 89, 118, 48, 5, 77, 16, 65, 290, 273, 33, 142, 197, 9, 5, 1, 4339, 298, 4, 783, 9, 37, 290, 7, 7, 38, 273, 11, 19, 80, 5541, 22, 5, 343, 400])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(X_train_tokens[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 299,    6,    3, 1059,  202,    9, 2119,   30,    1,  167,   55,\n",
       "         14,   47,   79, 6274,   42,  368,  114,  138,   14, 5103,   56,\n",
       "       4515,  153,    8,    1, 4233, 5799,  469,   68,    5,  262,   12,\n",
       "       2072,    6,   72, 2556,    5,  614,   71,    6, 5103,    1,    5,\n",
       "       1897,    1, 5540, 1469,   35,   67,   63,  203,  140,   65, 1151,\n",
       "          1,    4,    1,  223,  871,   29, 3195,   68,    4,    1, 5510,\n",
       "         10,  677,    2,   65, 1469,   50,   10,  210,    1,  398,    8,\n",
       "         60,    3, 1425, 3345,  762,    5, 3491,  175,    1,  368,   10,\n",
       "       1220,   30,  299,    3,  360,  347, 3471,  145,  133,    5, 8306,\n",
       "         27,    4,  125, 5103, 1425, 2563,    5,  299,   10,  525,   12,\n",
       "        106, 1540,    4,   56,  599,  101,   12,  299,    6,  225, 3994,\n",
       "         48,    3, 2244,   12,    9,  213])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(X_train_tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#no.of tokens in each review of train and test\n",
    "num_tokens = [len(tokens) for tokens in X_train_tokens + X_test_tokens]\n",
    "num_tokens = np.array(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "221.27714"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#average no.of tokens in each review of train and test\n",
    "np.mean(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2209"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#max no.of tokens in the whole dataset\n",
    "np.max(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "544"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_tokens = np.mean(num_tokens) + 2*np.std(num_tokens)\n",
    "max_tokens = int(max_tokens)\n",
    "max_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9453"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(num_tokens < max_tokens)/len(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#So about 95% of the reviews are less than 544 tokens/words length.\n",
    "#We are truncating(pre) other 5% to length of 544 tokens of both train and test whose length is greater\n",
    "#than 544"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pad = 'pre'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_pad = pad_sequences(X_train_tokens,maxlen = max_tokens,padding = pad,truncating = pad)\n",
    "#2d array of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_pad = pad_sequences(X_test_tokens,maxlen = max_tokens,padding = pad,truncating = pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 544)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 544)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 299,    6,    3, 1059,  202,    9, 2119,   30,    1,  167,   55,\n",
       "         14,   47,   79, 6274,   42,  368,  114,  138,   14, 5103,   56,\n",
       "       4515,  153,    8,    1, 4233, 5799,  469,   68,    5,  262,   12,\n",
       "       2072,    6,   72, 2556,    5,  614,   71,    6, 5103,    1,    5,\n",
       "       1897,    1, 5540, 1469,   35,   67,   63,  203,  140,   65, 1151,\n",
       "          1,    4,    1,  223,  871,   29, 3195,   68,    4,    1, 5510,\n",
       "         10,  677,    2,   65, 1469,   50,   10,  210,    1,  398,    8,\n",
       "         60,    3, 1425, 3345,  762,    5, 3491,  175,    1,  368,   10,\n",
       "       1220,   30,  299,    3,  360,  347, 3471,  145,  133,    5, 8306,\n",
       "         27,    4,  125, 5103, 1425, 2563,    5,  299,   10,  525,   12,\n",
       "        106, 1540,    4,   56,  599,  101,   12,  299,    6,  225, 3994,\n",
       "         48,    3, 2244,   12,    9,  213])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(X_train_tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,  299,\n",
       "          6,    3, 1059,  202,    9, 2119,   30,    1,  167,   55,   14,\n",
       "         47,   79, 6274,   42,  368,  114,  138,   14, 5103,   56, 4515,\n",
       "        153,    8,    1, 4233, 5799,  469,   68,    5,  262,   12, 2072,\n",
       "          6,   72, 2556,    5,  614,   71,    6, 5103,    1,    5, 1897,\n",
       "          1, 5540, 1469,   35,   67,   63,  203,  140,   65, 1151,    1,\n",
       "          4,    1,  223,  871,   29, 3195,   68,    4,    1, 5510,   10,\n",
       "        677,    2,   65, 1469,   50,   10,  210,    1,  398,    8,   60,\n",
       "          3, 1425, 3345,  762,    5, 3491,  175,    1,  368,   10, 1220,\n",
       "         30,  299,    3,  360,  347, 3471,  145,  133,    5, 8306,   27,\n",
       "          4,  125, 5103, 1425, 2563,    5,  299,   10,  525,   12,  106,\n",
       "       1540,    4,   56,  599,  101,   12,  299,    6,  225, 3994,   48,\n",
       "          3, 2244,   12,    9,  213])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(X_train_pad[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ...,  12,   9, 213],\n",
       "       [  0,   0,   0, ...,   5, 343, 400]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pad[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reverse mapping words from tokens\n",
    "idx = tokenizer.word_index\n",
    "inverse_map = dict(zip(idx.values(),idx.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokens_to_string(tokens):\n",
    "    words = [inverse_map[token] for token in tokens if token != 0]\n",
    "    \n",
    "    text = ' '.join(words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school life, such as \"Teachers\". My 35 years in the teaching profession lead me to believe that Bromwell High\\'s satire is much closer to reality than is \"Teachers\". The scramble to survive financially, the insightful students who can see right through their pathetic teachers\\' pomp, the pettiness of the whole situation, all remind me of the schools I knew and their students. When I saw the episode in which a student repeatedly tried to burn down the school, I immediately recalled ......... at .......... High. A classic line: INSPECTOR: I\\'m here to sack one of your teachers. STUDENT: Welcome to Bromwell High. I expect that many adults of my age think that Bromwell High is far fetched. What a pity that it isn\\'t!'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"high is a cartoon comedy it ran at the same time as some other programs about school life such as teachers my 35 years in the teaching profession lead me to believe that satire is much closer to reality than is teachers the to survive the insightful students who can see right through their pathetic the of the whole situation all remind me of the schools i knew and their students when i saw the episode in which a student repeatedly tried to burn down the school i immediately at high a classic line inspector i'm here to sack one of your teachers student welcome to high i expect that many adults of my age think that high is far fetched what a pity that it isn't\""
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_to_string(X_train_tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#As you can see, some preprocessing like tolower,\n",
    "#remove reg exp,html tags etc but no stop word removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers.embeddings import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Embedding(input_dim = num_words,\\\n",
    "                   output_dim = 8,\\\n",
    "                   input_length = max_tokens,\\\n",
    "                   name = 'layer_embedding'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.add(GRU(16,return_sequences = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(GRU(units = 8, return_sequences = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(GRU(units = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Dense(1,activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss = 'binary_crossentropy',optimizer = 'adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "layer_embedding (Embedding)  (None, 544, 8)            80000     \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 544, 16)           1200      \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 544, 8)            600       \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (None, 4)                 156       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 81,961\n",
      "Trainable params: 81,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23750 samples, validate on 1250 samples\n",
      "Epoch 1/3\n",
      "12992/23750 [===============>..............] - ETA: 3:26 - loss: 0.6870 - acc: 0.515 - ETA: 3:14 - loss: 0.6853 - acc: 0.539 - ETA: 3:05 - loss: 0.6851 - acc: 0.536 - ETA: 3:03 - loss: 0.6864 - acc: 0.527 - ETA: 3:01 - loss: 0.6852 - acc: 0.540 - ETA: 2:58 - loss: 0.6870 - acc: 0.523 - ETA: 2:57 - loss: 0.6859 - acc: 0.529 - ETA: 2:56 - loss: 0.6864 - acc: 0.523 - ETA: 2:54 - loss: 0.6864 - acc: 0.520 - ETA: 2:53 - loss: 0.6835 - acc: 0.542 - ETA: 2:52 - loss: 0.6823 - acc: 0.548 - ETA: 2:51 - loss: 0.6822 - acc: 0.546 - ETA: 2:51 - loss: 0.6816 - acc: 0.551 - ETA: 2:50 - loss: 0.6822 - acc: 0.548 - ETA: 2:49 - loss: 0.6812 - acc: 0.551 - ETA: 2:49 - loss: 0.6813 - acc: 0.550 - ETA: 2:48 - loss: 0.6823 - acc: 0.546 - ETA: 2:47 - loss: 0.6825 - acc: 0.543 - ETA: 2:47 - loss: 0.6827 - acc: 0.540 - ETA: 2:47 - loss: 0.6828 - acc: 0.538 - ETA: 2:47 - loss: 0.6832 - acc: 0.537 - ETA: 2:47 - loss: 0.6814 - acc: 0.544 - ETA: 2:47 - loss: 0.6814 - acc: 0.542 - ETA: 2:46 - loss: 0.6809 - acc: 0.541 - ETA: 2:46 - loss: 0.6804 - acc: 0.542 - ETA: 2:45 - loss: 0.6804 - acc: 0.542 - ETA: 2:45 - loss: 0.6806 - acc: 0.539 - ETA: 2:44 - loss: 0.6809 - acc: 0.539 - ETA: 2:44 - loss: 0.6806 - acc: 0.542 - ETA: 2:44 - loss: 0.6799 - acc: 0.544 - ETA: 2:43 - loss: 0.6789 - acc: 0.547 - ETA: 2:43 - loss: 0.6779 - acc: 0.552 - ETA: 2:42 - loss: 0.6774 - acc: 0.555 - ETA: 2:42 - loss: 0.6767 - acc: 0.557 - ETA: 2:42 - loss: 0.6757 - acc: 0.562 - ETA: 2:41 - loss: 0.6754 - acc: 0.562 - ETA: 2:41 - loss: 0.6752 - acc: 0.564 - ETA: 2:41 - loss: 0.6745 - acc: 0.567 - ETA: 2:40 - loss: 0.6740 - acc: 0.571 - ETA: 2:39 - loss: 0.6737 - acc: 0.571 - ETA: 2:39 - loss: 0.6734 - acc: 0.572 - ETA: 2:39 - loss: 0.6722 - acc: 0.574 - ETA: 2:38 - loss: 0.6716 - acc: 0.576 - ETA: 2:38 - loss: 0.6710 - acc: 0.578 - ETA: 2:37 - loss: 0.6708 - acc: 0.579 - ETA: 2:37 - loss: 0.6701 - acc: 0.579 - ETA: 2:37 - loss: 0.6695 - acc: 0.581 - ETA: 2:38 - loss: 0.6680 - acc: 0.585 - ETA: 2:38 - loss: 0.6659 - acc: 0.589 - ETA: 2:38 - loss: 0.6635 - acc: 0.591 - ETA: 2:39 - loss: 0.6625 - acc: 0.592 - ETA: 2:39 - loss: 0.6611 - acc: 0.594 - ETA: 2:39 - loss: 0.6596 - acc: 0.596 - ETA: 2:39 - loss: 0.6571 - acc: 0.599 - ETA: 2:38 - loss: 0.6534 - acc: 0.602 - ETA: 2:38 - loss: 0.6500 - acc: 0.607 - ETA: 2:38 - loss: 0.6497 - acc: 0.608 - ETA: 2:38 - loss: 0.6480 - acc: 0.610 - ETA: 2:38 - loss: 0.6454 - acc: 0.613 - ETA: 2:37 - loss: 0.6446 - acc: 0.613 - ETA: 2:37 - loss: 0.6430 - acc: 0.615 - ETA: 2:36 - loss: 0.6405 - acc: 0.618 - ETA: 2:36 - loss: 0.6367 - acc: 0.621 - ETA: 2:36 - loss: 0.6352 - acc: 0.623 - ETA: 2:36 - loss: 0.6328 - acc: 0.625 - ETA: 2:35 - loss: 0.6316 - acc: 0.627 - ETA: 2:34 - loss: 0.6286 - acc: 0.630 - ETA: 2:33 - loss: 0.6268 - acc: 0.632 - ETA: 2:33 - loss: 0.6249 - acc: 0.634 - ETA: 2:32 - loss: 0.6229 - acc: 0.635 - ETA: 2:31 - loss: 0.6188 - acc: 0.639 - ETA: 2:31 - loss: 0.6166 - acc: 0.641 - ETA: 2:30 - loss: 0.6146 - acc: 0.643 - ETA: 2:29 - loss: 0.6103 - acc: 0.647 - ETA: 2:29 - loss: 0.6075 - acc: 0.649 - ETA: 2:28 - loss: 0.6045 - acc: 0.651 - ETA: 2:27 - loss: 0.6028 - acc: 0.653 - ETA: 2:27 - loss: 0.6010 - acc: 0.655 - ETA: 2:26 - loss: 0.6005 - acc: 0.656 - ETA: 2:25 - loss: 0.6001 - acc: 0.657 - ETA: 2:25 - loss: 0.6009 - acc: 0.657 - ETA: 2:24 - loss: 0.6003 - acc: 0.658 - ETA: 2:24 - loss: 0.5979 - acc: 0.660 - ETA: 2:24 - loss: 0.5964 - acc: 0.661 - ETA: 2:24 - loss: 0.5948 - acc: 0.663 - ETA: 2:24 - loss: 0.5932 - acc: 0.664 - ETA: 2:23 - loss: 0.5903 - acc: 0.667 - ETA: 2:23 - loss: 0.5887 - acc: 0.668 - ETA: 2:23 - loss: 0.5868 - acc: 0.670 - ETA: 2:23 - loss: 0.5866 - acc: 0.671 - ETA: 2:22 - loss: 0.5845 - acc: 0.673 - ETA: 2:22 - loss: 0.5824 - acc: 0.675 - ETA: 2:21 - loss: 0.5812 - acc: 0.677 - ETA: 2:21 - loss: 0.5796 - acc: 0.678 - ETA: 2:20 - loss: 0.5779 - acc: 0.680 - ETA: 2:21 - loss: 0.5768 - acc: 0.680 - ETA: 2:20 - loss: 0.5769 - acc: 0.680 - ETA: 2:20 - loss: 0.5757 - acc: 0.682 - ETA: 2:20 - loss: 0.5742 - acc: 0.683 - ETA: 2:20 - loss: 0.5729 - acc: 0.684 - ETA: 2:20 - loss: 0.5716 - acc: 0.685 - ETA: 2:19 - loss: 0.5705 - acc: 0.686 - ETA: 2:19 - loss: 0.5684 - acc: 0.688 - ETA: 2:19 - loss: 0.5680 - acc: 0.688 - ETA: 2:19 - loss: 0.5658 - acc: 0.691 - ETA: 2:18 - loss: 0.5649 - acc: 0.691 - ETA: 2:18 - loss: 0.5630 - acc: 0.693 - ETA: 2:18 - loss: 0.5621 - acc: 0.694 - ETA: 2:17 - loss: 0.5604 - acc: 0.695 - ETA: 2:17 - loss: 0.5594 - acc: 0.697 - ETA: 2:17 - loss: 0.5584 - acc: 0.697 - ETA: 2:17 - loss: 0.5563 - acc: 0.699 - ETA: 2:16 - loss: 0.5543 - acc: 0.700 - ETA: 2:16 - loss: 0.5535 - acc: 0.701 - ETA: 2:16 - loss: 0.5524 - acc: 0.702 - ETA: 2:15 - loss: 0.5518 - acc: 0.702 - ETA: 2:15 - loss: 0.5505 - acc: 0.703 - ETA: 2:14 - loss: 0.5495 - acc: 0.704 - ETA: 2:14 - loss: 0.5477 - acc: 0.706 - ETA: 2:13 - loss: 0.5463 - acc: 0.707 - ETA: 2:13 - loss: 0.5458 - acc: 0.708 - ETA: 2:12 - loss: 0.5439 - acc: 0.710 - ETA: 2:12 - loss: 0.5429 - acc: 0.710 - ETA: 2:12 - loss: 0.5423 - acc: 0.711 - ETA: 2:12 - loss: 0.5405 - acc: 0.712 - ETA: 2:11 - loss: 0.5394 - acc: 0.713 - ETA: 2:11 - loss: 0.5380 - acc: 0.714 - ETA: 2:11 - loss: 0.5375 - acc: 0.715 - ETA: 2:11 - loss: 0.5362 - acc: 0.716 - ETA: 2:10 - loss: 0.5348 - acc: 0.717 - ETA: 2:09 - loss: 0.5333 - acc: 0.718 - ETA: 2:09 - loss: 0.5329 - acc: 0.719 - ETA: 2:09 - loss: 0.5347 - acc: 0.719 - ETA: 2:08 - loss: 0.5347 - acc: 0.719 - ETA: 2:07 - loss: 0.5341 - acc: 0.720 - ETA: 2:07 - loss: 0.5329 - acc: 0.721 - ETA: 2:06 - loss: 0.5328 - acc: 0.721 - ETA: 2:06 - loss: 0.5318 - acc: 0.722 - ETA: 2:06 - loss: 0.5322 - acc: 0.722 - ETA: 2:05 - loss: 0.5324 - acc: 0.721 - ETA: 2:05 - loss: 0.5316 - acc: 0.722 - ETA: 2:04 - loss: 0.5312 - acc: 0.723 - ETA: 2:04 - loss: 0.5301 - acc: 0.724 - ETA: 2:03 - loss: 0.5296 - acc: 0.724 - ETA: 2:03 - loss: 0.5288 - acc: 0.725 - ETA: 2:03 - loss: 0.5286 - acc: 0.725 - ETA: 2:02 - loss: 0.5273 - acc: 0.726 - ETA: 2:02 - loss: 0.5274 - acc: 0.726 - ETA: 2:01 - loss: 0.5265 - acc: 0.727 - ETA: 2:01 - loss: 0.5253 - acc: 0.728 - ETA: 2:00 - loss: 0.5249 - acc: 0.729 - ETA: 2:00 - loss: 0.5237 - acc: 0.730 - ETA: 1:59 - loss: 0.5234 - acc: 0.730 - ETA: 1:59 - loss: 0.5230 - acc: 0.730 - ETA: 1:58 - loss: 0.5225 - acc: 0.731 - ETA: 1:57 - loss: 0.5218 - acc: 0.731 - ETA: 1:57 - loss: 0.5211 - acc: 0.732 - ETA: 1:57 - loss: 0.5207 - acc: 0.732 - ETA: 1:56 - loss: 0.5197 - acc: 0.733 - ETA: 1:56 - loss: 0.5189 - acc: 0.734 - ETA: 1:55 - loss: 0.5181 - acc: 0.734 - ETA: 1:55 - loss: 0.5177 - acc: 0.734 - ETA: 1:55 - loss: 0.5174 - acc: 0.735 - ETA: 1:54 - loss: 0.5165 - acc: 0.735 - ETA: 1:53 - loss: 0.5159 - acc: 0.736 - ETA: 1:53 - loss: 0.5155 - acc: 0.736 - ETA: 1:52 - loss: 0.5154 - acc: 0.736 - ETA: 1:52 - loss: 0.5148 - acc: 0.737 - ETA: 1:51 - loss: 0.5137 - acc: 0.738 - ETA: 1:50 - loss: 0.5127 - acc: 0.739 - ETA: 1:50 - loss: 0.5127 - acc: 0.739 - ETA: 1:49 - loss: 0.5119 - acc: 0.740 - ETA: 1:49 - loss: 0.5111 - acc: 0.740 - ETA: 1:48 - loss: 0.5101 - acc: 0.741 - ETA: 1:48 - loss: 0.5091 - acc: 0.742 - ETA: 1:47 - loss: 0.5085 - acc: 0.743 - ETA: 1:46 - loss: 0.5078 - acc: 0.743 - ETA: 1:46 - loss: 0.5069 - acc: 0.744 - ETA: 1:45 - loss: 0.5067 - acc: 0.744 - ETA: 1:44 - loss: 0.5067 - acc: 0.744 - ETA: 1:44 - loss: 0.5064 - acc: 0.744 - ETA: 1:43 - loss: 0.5062 - acc: 0.745 - ETA: 1:43 - loss: 0.5053 - acc: 0.745 - ETA: 1:42 - loss: 0.5046 - acc: 0.746 - ETA: 1:41 - loss: 0.5042 - acc: 0.746 - ETA: 1:41 - loss: 0.5030 - acc: 0.746 - ETA: 1:40 - loss: 0.5022 - acc: 0.747 - ETA: 1:40 - loss: 0.5014 - acc: 0.748 - ETA: 1:39 - loss: 0.5016 - acc: 0.748 - ETA: 1:38 - loss: 0.5012 - acc: 0.748 - ETA: 1:38 - loss: 0.5003 - acc: 0.749 - ETA: 1:37 - loss: 0.4999 - acc: 0.749 - ETA: 1:37 - loss: 0.4991 - acc: 0.750 - ETA: 1:36 - loss: 0.4989 - acc: 0.750 - ETA: 1:35 - loss: 0.4983 - acc: 0.750 - ETA: 1:35 - loss: 0.4979 - acc: 0.750 - ETA: 1:34 - loss: 0.4978 - acc: 0.751 - ETA: 1:34 - loss: 0.4971 - acc: 0.751 - ETA: 1:33 - loss: 0.4968 - acc: 0.751 - ETA: 1:32 - loss: 0.4963 - acc: 0.752 - ETA: 1:32 - loss: 0.4962 - acc: 0.752 - ETA: 1:31 - loss: 0.4960 - acc: 0.752 - ETA: 1:31 - loss: 0.4958 - acc: 0.75323750/23750 [==============================] - ETA: 1:30 - loss: 0.4957 - acc: 0.753 - ETA: 1:30 - loss: 0.4952 - acc: 0.753 - ETA: 1:30 - loss: 0.4951 - acc: 0.753 - ETA: 1:29 - loss: 0.4946 - acc: 0.754 - ETA: 1:29 - loss: 0.4936 - acc: 0.754 - ETA: 1:28 - loss: 0.4933 - acc: 0.755 - ETA: 1:27 - loss: 0.4928 - acc: 0.755 - ETA: 1:27 - loss: 0.4927 - acc: 0.755 - ETA: 1:26 - loss: 0.4918 - acc: 0.756 - ETA: 1:26 - loss: 0.4915 - acc: 0.756 - ETA: 1:25 - loss: 0.4910 - acc: 0.756 - ETA: 1:25 - loss: 0.4907 - acc: 0.757 - ETA: 1:24 - loss: 0.4899 - acc: 0.757 - ETA: 1:24 - loss: 0.4890 - acc: 0.758 - ETA: 1:23 - loss: 0.4890 - acc: 0.758 - ETA: 1:23 - loss: 0.4881 - acc: 0.758 - ETA: 1:22 - loss: 0.4876 - acc: 0.759 - ETA: 1:22 - loss: 0.4872 - acc: 0.759 - ETA: 1:21 - loss: 0.4873 - acc: 0.759 - ETA: 1:21 - loss: 0.4865 - acc: 0.760 - ETA: 1:20 - loss: 0.4859 - acc: 0.760 - ETA: 1:20 - loss: 0.4851 - acc: 0.761 - ETA: 1:19 - loss: 0.4849 - acc: 0.761 - ETA: 1:19 - loss: 0.4843 - acc: 0.761 - ETA: 1:18 - loss: 0.4836 - acc: 0.762 - ETA: 1:18 - loss: 0.4835 - acc: 0.762 - ETA: 1:17 - loss: 0.4833 - acc: 0.762 - ETA: 1:16 - loss: 0.4831 - acc: 0.762 - ETA: 1:16 - loss: 0.4824 - acc: 0.762 - ETA: 1:15 - loss: 0.4818 - acc: 0.763 - ETA: 1:15 - loss: 0.4809 - acc: 0.764 - ETA: 1:14 - loss: 0.4803 - acc: 0.764 - ETA: 1:14 - loss: 0.4797 - acc: 0.764 - ETA: 1:13 - loss: 0.4797 - acc: 0.764 - ETA: 1:13 - loss: 0.4799 - acc: 0.764 - ETA: 1:12 - loss: 0.4797 - acc: 0.765 - ETA: 1:11 - loss: 0.4789 - acc: 0.765 - ETA: 1:11 - loss: 0.4786 - acc: 0.765 - ETA: 1:10 - loss: 0.4782 - acc: 0.766 - ETA: 1:10 - loss: 0.4778 - acc: 0.766 - ETA: 1:09 - loss: 0.4779 - acc: 0.766 - ETA: 1:09 - loss: 0.4773 - acc: 0.766 - ETA: 1:08 - loss: 0.4769 - acc: 0.766 - ETA: 1:08 - loss: 0.4763 - acc: 0.767 - ETA: 1:07 - loss: 0.4762 - acc: 0.767 - ETA: 1:07 - loss: 0.4756 - acc: 0.767 - ETA: 1:06 - loss: 0.4752 - acc: 0.768 - ETA: 1:05 - loss: 0.4748 - acc: 0.768 - ETA: 1:05 - loss: 0.4743 - acc: 0.768 - ETA: 1:04 - loss: 0.4741 - acc: 0.769 - ETA: 1:04 - loss: 0.4739 - acc: 0.769 - ETA: 1:03 - loss: 0.4734 - acc: 0.769 - ETA: 1:03 - loss: 0.4731 - acc: 0.769 - ETA: 1:02 - loss: 0.4724 - acc: 0.770 - ETA: 1:01 - loss: 0.4721 - acc: 0.770 - ETA: 1:01 - loss: 0.4717 - acc: 0.770 - ETA: 1:00 - loss: 0.4714 - acc: 0.771 - ETA: 1:00 - loss: 0.4707 - acc: 0.771 - ETA: 59s - loss: 0.4701 - acc: 0.772 - ETA: 59s - loss: 0.4698 - acc: 0.77 - ETA: 58s - loss: 0.4692 - acc: 0.77 - ETA: 58s - loss: 0.4693 - acc: 0.77 - ETA: 57s - loss: 0.4690 - acc: 0.77 - ETA: 57s - loss: 0.4686 - acc: 0.77 - ETA: 56s - loss: 0.4683 - acc: 0.77 - ETA: 56s - loss: 0.4680 - acc: 0.77 - ETA: 55s - loss: 0.4676 - acc: 0.77 - ETA: 55s - loss: 0.4670 - acc: 0.77 - ETA: 54s - loss: 0.4662 - acc: 0.77 - ETA: 54s - loss: 0.4660 - acc: 0.77 - ETA: 53s - loss: 0.4659 - acc: 0.77 - ETA: 53s - loss: 0.4660 - acc: 0.77 - ETA: 52s - loss: 0.4658 - acc: 0.77 - ETA: 51s - loss: 0.4653 - acc: 0.77 - ETA: 51s - loss: 0.4651 - acc: 0.77 - ETA: 50s - loss: 0.4644 - acc: 0.77 - ETA: 50s - loss: 0.4640 - acc: 0.77 - ETA: 49s - loss: 0.4636 - acc: 0.77 - ETA: 49s - loss: 0.4635 - acc: 0.77 - ETA: 48s - loss: 0.4631 - acc: 0.77 - ETA: 47s - loss: 0.4630 - acc: 0.77 - ETA: 47s - loss: 0.4625 - acc: 0.77 - ETA: 46s - loss: 0.4620 - acc: 0.77 - ETA: 46s - loss: 0.4619 - acc: 0.77 - ETA: 45s - loss: 0.4617 - acc: 0.77 - ETA: 45s - loss: 0.4613 - acc: 0.77 - ETA: 44s - loss: 0.4607 - acc: 0.77 - ETA: 43s - loss: 0.4604 - acc: 0.77 - ETA: 43s - loss: 0.4601 - acc: 0.78 - ETA: 42s - loss: 0.4596 - acc: 0.78 - ETA: 42s - loss: 0.4591 - acc: 0.78 - ETA: 41s - loss: 0.4591 - acc: 0.78 - ETA: 41s - loss: 0.4590 - acc: 0.78 - ETA: 40s - loss: 0.4585 - acc: 0.78 - ETA: 40s - loss: 0.4581 - acc: 0.78 - ETA: 39s - loss: 0.4577 - acc: 0.78 - ETA: 38s - loss: 0.4569 - acc: 0.78 - ETA: 38s - loss: 0.4563 - acc: 0.78 - ETA: 37s - loss: 0.4561 - acc: 0.78 - ETA: 37s - loss: 0.4560 - acc: 0.78 - ETA: 36s - loss: 0.4558 - acc: 0.78 - ETA: 36s - loss: 0.4556 - acc: 0.78 - ETA: 35s - loss: 0.4553 - acc: 0.78 - ETA: 35s - loss: 0.4549 - acc: 0.78 - ETA: 34s - loss: 0.4545 - acc: 0.78 - ETA: 33s - loss: 0.4548 - acc: 0.78 - ETA: 33s - loss: 0.4548 - acc: 0.78 - ETA: 32s - loss: 0.4543 - acc: 0.78 - ETA: 32s - loss: 0.4541 - acc: 0.78 - ETA: 31s - loss: 0.4538 - acc: 0.78 - ETA: 31s - loss: 0.4535 - acc: 0.78 - ETA: 30s - loss: 0.4531 - acc: 0.78 - ETA: 30s - loss: 0.4527 - acc: 0.78 - ETA: 29s - loss: 0.4520 - acc: 0.78 - ETA: 28s - loss: 0.4517 - acc: 0.78 - ETA: 28s - loss: 0.4515 - acc: 0.78 - ETA: 27s - loss: 0.4508 - acc: 0.78 - ETA: 27s - loss: 0.4507 - acc: 0.78 - ETA: 26s - loss: 0.4504 - acc: 0.78 - ETA: 26s - loss: 0.4498 - acc: 0.78 - ETA: 25s - loss: 0.4495 - acc: 0.78 - ETA: 25s - loss: 0.4492 - acc: 0.78 - ETA: 24s - loss: 0.4488 - acc: 0.78 - ETA: 23s - loss: 0.4487 - acc: 0.78 - ETA: 23s - loss: 0.4484 - acc: 0.78 - ETA: 22s - loss: 0.4486 - acc: 0.78 - ETA: 22s - loss: 0.4481 - acc: 0.78 - ETA: 21s - loss: 0.4475 - acc: 0.78 - ETA: 21s - loss: 0.4473 - acc: 0.78 - ETA: 20s - loss: 0.4471 - acc: 0.78 - ETA: 20s - loss: 0.4467 - acc: 0.78 - ETA: 19s - loss: 0.4465 - acc: 0.78 - ETA: 19s - loss: 0.4464 - acc: 0.78 - ETA: 18s - loss: 0.4465 - acc: 0.78 - ETA: 17s - loss: 0.4464 - acc: 0.78 - ETA: 17s - loss: 0.4460 - acc: 0.78 - ETA: 16s - loss: 0.4456 - acc: 0.79 - ETA: 16s - loss: 0.4453 - acc: 0.79 - ETA: 15s - loss: 0.4450 - acc: 0.79 - ETA: 15s - loss: 0.4446 - acc: 0.79 - ETA: 14s - loss: 0.4442 - acc: 0.79 - ETA: 14s - loss: 0.4438 - acc: 0.79 - ETA: 13s - loss: 0.4433 - acc: 0.79 - ETA: 13s - loss: 0.4430 - acc: 0.79 - ETA: 12s - loss: 0.4427 - acc: 0.79 - ETA: 11s - loss: 0.4421 - acc: 0.79 - ETA: 11s - loss: 0.4422 - acc: 0.79 - ETA: 10s - loss: 0.4417 - acc: 0.79 - ETA: 10s - loss: 0.4413 - acc: 0.79 - ETA: 9s - loss: 0.4410 - acc: 0.7935 - ETA: 9s - loss: 0.4406 - acc: 0.793 - ETA: 8s - loss: 0.4405 - acc: 0.793 - ETA: 8s - loss: 0.4400 - acc: 0.794 - ETA: 7s - loss: 0.4401 - acc: 0.794 - ETA: 7s - loss: 0.4399 - acc: 0.794 - ETA: 6s - loss: 0.4397 - acc: 0.794 - ETA: 5s - loss: 0.4394 - acc: 0.794 - ETA: 5s - loss: 0.4391 - acc: 0.794 - ETA: 4s - loss: 0.4388 - acc: 0.795 - ETA: 4s - loss: 0.4387 - acc: 0.795 - ETA: 3s - loss: 0.4388 - acc: 0.794 - ETA: 3s - loss: 0.4387 - acc: 0.795 - ETA: 2s - loss: 0.4386 - acc: 0.795 - ETA: 2s - loss: 0.4384 - acc: 0.795 - ETA: 1s - loss: 0.4382 - acc: 0.795 - ETA: 1s - loss: 0.4380 - acc: 0.795 - ETA: 0s - loss: 0.4381 - acc: 0.795 - ETA: 0s - loss: 0.4376 - acc: 0.795 - 202s 8ms/step - loss: 0.4375 - acc: 0.7959 - val_loss: 0.3874 - val_acc: 0.8304\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13056/23750 [===============>..............] - ETA: 3:03 - loss: 0.3273 - acc: 0.875 - ETA: 3:04 - loss: 0.3036 - acc: 0.875 - ETA: 3:02 - loss: 0.2849 - acc: 0.890 - ETA: 3:01 - loss: 0.2958 - acc: 0.882 - ETA: 3:00 - loss: 0.3237 - acc: 0.865 - ETA: 3:00 - loss: 0.3135 - acc: 0.875 - ETA: 3:00 - loss: 0.3174 - acc: 0.875 - ETA: 2:59 - loss: 0.3176 - acc: 0.877 - ETA: 2:58 - loss: 0.3036 - acc: 0.885 - ETA: 2:58 - loss: 0.2942 - acc: 0.892 - ETA: 2:58 - loss: 0.2881 - acc: 0.897 - ETA: 2:57 - loss: 0.2823 - acc: 0.898 - ETA: 2:57 - loss: 0.2790 - acc: 0.900 - ETA: 2:56 - loss: 0.2813 - acc: 0.899 - ETA: 2:56 - loss: 0.2848 - acc: 0.899 - ETA: 2:56 - loss: 0.2916 - acc: 0.895 - ETA: 2:55 - loss: 0.2914 - acc: 0.893 - ETA: 2:55 - loss: 0.2892 - acc: 0.894 - ETA: 2:55 - loss: 0.2866 - acc: 0.894 - ETA: 2:54 - loss: 0.2832 - acc: 0.896 - ETA: 2:53 - loss: 0.2858 - acc: 0.895 - ETA: 2:53 - loss: 0.2831 - acc: 0.897 - ETA: 2:52 - loss: 0.2855 - acc: 0.895 - ETA: 2:52 - loss: 0.2813 - acc: 0.897 - ETA: 2:52 - loss: 0.2842 - acc: 0.894 - ETA: 2:51 - loss: 0.2856 - acc: 0.893 - ETA: 2:50 - loss: 0.2829 - acc: 0.895 - ETA: 2:50 - loss: 0.2852 - acc: 0.894 - ETA: 2:50 - loss: 0.2884 - acc: 0.892 - ETA: 2:49 - loss: 0.2892 - acc: 0.891 - ETA: 2:48 - loss: 0.2884 - acc: 0.891 - ETA: 2:49 - loss: 0.2891 - acc: 0.891 - ETA: 2:49 - loss: 0.2881 - acc: 0.892 - ETA: 2:50 - loss: 0.2859 - acc: 0.893 - ETA: 2:54 - loss: 0.2867 - acc: 0.892 - ETA: 2:55 - loss: 0.2835 - acc: 0.894 - ETA: 2:58 - loss: 0.2831 - acc: 0.894 - ETA: 2:58 - loss: 0.2807 - acc: 0.896 - ETA: 2:57 - loss: 0.2828 - acc: 0.895 - ETA: 2:56 - loss: 0.2820 - acc: 0.895 - ETA: 2:55 - loss: 0.2802 - acc: 0.897 - ETA: 2:55 - loss: 0.2809 - acc: 0.896 - ETA: 2:54 - loss: 0.2825 - acc: 0.896 - ETA: 2:56 - loss: 0.2820 - acc: 0.897 - ETA: 2:58 - loss: 0.2833 - acc: 0.896 - ETA: 2:57 - loss: 0.2818 - acc: 0.897 - ETA: 2:56 - loss: 0.2816 - acc: 0.897 - ETA: 2:56 - loss: 0.2809 - acc: 0.898 - ETA: 2:55 - loss: 0.2808 - acc: 0.898 - ETA: 2:54 - loss: 0.2808 - acc: 0.897 - ETA: 2:54 - loss: 0.2802 - acc: 0.898 - ETA: 2:53 - loss: 0.2804 - acc: 0.897 - ETA: 2:52 - loss: 0.2812 - acc: 0.896 - ETA: 2:51 - loss: 0.2806 - acc: 0.897 - ETA: 2:51 - loss: 0.2806 - acc: 0.896 - ETA: 2:50 - loss: 0.2787 - acc: 0.898 - ETA: 2:49 - loss: 0.2792 - acc: 0.897 - ETA: 2:49 - loss: 0.2802 - acc: 0.896 - ETA: 2:48 - loss: 0.2810 - acc: 0.896 - ETA: 2:47 - loss: 0.2802 - acc: 0.896 - ETA: 2:47 - loss: 0.2792 - acc: 0.897 - ETA: 2:46 - loss: 0.2785 - acc: 0.898 - ETA: 2:46 - loss: 0.2789 - acc: 0.897 - ETA: 2:45 - loss: 0.2802 - acc: 0.896 - ETA: 2:45 - loss: 0.2805 - acc: 0.896 - ETA: 2:44 - loss: 0.2803 - acc: 0.896 - ETA: 2:43 - loss: 0.2792 - acc: 0.897 - ETA: 2:44 - loss: 0.2806 - acc: 0.897 - ETA: 2:45 - loss: 0.2821 - acc: 0.896 - ETA: 2:47 - loss: 0.2829 - acc: 0.895 - ETA: 2:48 - loss: 0.2824 - acc: 0.895 - ETA: 2:49 - loss: 0.2824 - acc: 0.895 - ETA: 2:49 - loss: 0.2812 - acc: 0.895 - ETA: 2:48 - loss: 0.2810 - acc: 0.896 - ETA: 2:47 - loss: 0.2794 - acc: 0.896 - ETA: 2:46 - loss: 0.2793 - acc: 0.896 - ETA: 2:46 - loss: 0.2792 - acc: 0.896 - ETA: 2:45 - loss: 0.2779 - acc: 0.897 - ETA: 2:44 - loss: 0.2764 - acc: 0.897 - ETA: 2:43 - loss: 0.2751 - acc: 0.898 - ETA: 2:42 - loss: 0.2753 - acc: 0.898 - ETA: 2:41 - loss: 0.2758 - acc: 0.898 - ETA: 2:41 - loss: 0.2751 - acc: 0.898 - ETA: 2:40 - loss: 0.2747 - acc: 0.898 - ETA: 2:39 - loss: 0.2734 - acc: 0.899 - ETA: 2:38 - loss: 0.2744 - acc: 0.899 - ETA: 2:38 - loss: 0.2754 - acc: 0.898 - ETA: 2:37 - loss: 0.2748 - acc: 0.899 - ETA: 2:36 - loss: 0.2743 - acc: 0.899 - ETA: 2:35 - loss: 0.2741 - acc: 0.899 - ETA: 2:35 - loss: 0.2726 - acc: 0.900 - ETA: 2:34 - loss: 0.2733 - acc: 0.899 - ETA: 2:33 - loss: 0.2730 - acc: 0.900 - ETA: 2:32 - loss: 0.2737 - acc: 0.900 - ETA: 2:32 - loss: 0.2735 - acc: 0.900 - ETA: 2:31 - loss: 0.2736 - acc: 0.900 - ETA: 2:30 - loss: 0.2736 - acc: 0.900 - ETA: 2:30 - loss: 0.2753 - acc: 0.899 - ETA: 2:29 - loss: 0.2757 - acc: 0.899 - ETA: 2:28 - loss: 0.2756 - acc: 0.899 - ETA: 2:28 - loss: 0.2748 - acc: 0.899 - ETA: 2:27 - loss: 0.2747 - acc: 0.899 - ETA: 2:26 - loss: 0.2747 - acc: 0.899 - ETA: 2:26 - loss: 0.2767 - acc: 0.898 - ETA: 2:25 - loss: 0.2770 - acc: 0.898 - ETA: 2:24 - loss: 0.2778 - acc: 0.898 - ETA: 2:24 - loss: 0.2780 - acc: 0.898 - ETA: 2:23 - loss: 0.2778 - acc: 0.898 - ETA: 2:22 - loss: 0.2781 - acc: 0.897 - ETA: 2:22 - loss: 0.2776 - acc: 0.898 - ETA: 2:21 - loss: 0.2770 - acc: 0.898 - ETA: 2:20 - loss: 0.2768 - acc: 0.898 - ETA: 2:20 - loss: 0.2774 - acc: 0.897 - ETA: 2:19 - loss: 0.2785 - acc: 0.896 - ETA: 2:19 - loss: 0.2785 - acc: 0.896 - ETA: 2:18 - loss: 0.2785 - acc: 0.896 - ETA: 2:17 - loss: 0.2782 - acc: 0.896 - ETA: 2:17 - loss: 0.2776 - acc: 0.897 - ETA: 2:16 - loss: 0.2772 - acc: 0.897 - ETA: 2:15 - loss: 0.2770 - acc: 0.897 - ETA: 2:15 - loss: 0.2773 - acc: 0.897 - ETA: 2:14 - loss: 0.2779 - acc: 0.897 - ETA: 2:14 - loss: 0.2776 - acc: 0.897 - ETA: 2:13 - loss: 0.2781 - acc: 0.896 - ETA: 2:12 - loss: 0.2782 - acc: 0.896 - ETA: 2:12 - loss: 0.2775 - acc: 0.896 - ETA: 2:11 - loss: 0.2770 - acc: 0.897 - ETA: 2:11 - loss: 0.2779 - acc: 0.896 - ETA: 2:10 - loss: 0.2790 - acc: 0.896 - ETA: 2:09 - loss: 0.2783 - acc: 0.896 - ETA: 2:09 - loss: 0.2777 - acc: 0.896 - ETA: 2:08 - loss: 0.2773 - acc: 0.897 - ETA: 2:07 - loss: 0.2774 - acc: 0.896 - ETA: 2:07 - loss: 0.2774 - acc: 0.896 - ETA: 2:06 - loss: 0.2769 - acc: 0.897 - ETA: 2:06 - loss: 0.2765 - acc: 0.897 - ETA: 2:05 - loss: 0.2760 - acc: 0.897 - ETA: 2:05 - loss: 0.2756 - acc: 0.897 - ETA: 2:04 - loss: 0.2750 - acc: 0.898 - ETA: 2:04 - loss: 0.2763 - acc: 0.897 - ETA: 2:04 - loss: 0.2759 - acc: 0.897 - ETA: 2:04 - loss: 0.2767 - acc: 0.897 - ETA: 2:03 - loss: 0.2760 - acc: 0.897 - ETA: 2:02 - loss: 0.2760 - acc: 0.898 - ETA: 2:02 - loss: 0.2761 - acc: 0.898 - ETA: 2:01 - loss: 0.2756 - acc: 0.898 - ETA: 2:01 - loss: 0.2758 - acc: 0.898 - ETA: 2:01 - loss: 0.2769 - acc: 0.897 - ETA: 2:00 - loss: 0.2762 - acc: 0.898 - ETA: 2:00 - loss: 0.2759 - acc: 0.898 - ETA: 1:59 - loss: 0.2756 - acc: 0.898 - ETA: 1:59 - loss: 0.2762 - acc: 0.898 - ETA: 1:58 - loss: 0.2760 - acc: 0.898 - ETA: 1:58 - loss: 0.2758 - acc: 0.898 - ETA: 1:58 - loss: 0.2758 - acc: 0.898 - ETA: 1:57 - loss: 0.2756 - acc: 0.898 - ETA: 1:57 - loss: 0.2747 - acc: 0.898 - ETA: 1:56 - loss: 0.2745 - acc: 0.898 - ETA: 1:56 - loss: 0.2744 - acc: 0.898 - ETA: 1:56 - loss: 0.2745 - acc: 0.898 - ETA: 1:55 - loss: 0.2743 - acc: 0.899 - ETA: 1:55 - loss: 0.2742 - acc: 0.899 - ETA: 1:54 - loss: 0.2742 - acc: 0.899 - ETA: 1:54 - loss: 0.2743 - acc: 0.898 - ETA: 1:54 - loss: 0.2746 - acc: 0.898 - ETA: 1:53 - loss: 0.2741 - acc: 0.899 - ETA: 1:52 - loss: 0.2736 - acc: 0.899 - ETA: 1:52 - loss: 0.2734 - acc: 0.899 - ETA: 1:51 - loss: 0.2735 - acc: 0.899 - ETA: 1:51 - loss: 0.2727 - acc: 0.899 - ETA: 1:51 - loss: 0.2722 - acc: 0.899 - ETA: 1:50 - loss: 0.2730 - acc: 0.899 - ETA: 1:50 - loss: 0.2740 - acc: 0.899 - ETA: 1:49 - loss: 0.2736 - acc: 0.899 - ETA: 1:49 - loss: 0.2748 - acc: 0.898 - ETA: 1:48 - loss: 0.2748 - acc: 0.898 - ETA: 1:48 - loss: 0.2748 - acc: 0.898 - ETA: 1:47 - loss: 0.2750 - acc: 0.898 - ETA: 1:47 - loss: 0.2742 - acc: 0.898 - ETA: 1:46 - loss: 0.2740 - acc: 0.898 - ETA: 1:46 - loss: 0.2736 - acc: 0.899 - ETA: 1:45 - loss: 0.2734 - acc: 0.899 - ETA: 1:45 - loss: 0.2731 - acc: 0.899 - ETA: 1:44 - loss: 0.2728 - acc: 0.899 - ETA: 1:43 - loss: 0.2733 - acc: 0.899 - ETA: 1:43 - loss: 0.2733 - acc: 0.899 - ETA: 1:42 - loss: 0.2734 - acc: 0.899 - ETA: 1:42 - loss: 0.2731 - acc: 0.899 - ETA: 1:41 - loss: 0.2730 - acc: 0.899 - ETA: 1:40 - loss: 0.2727 - acc: 0.899 - ETA: 1:40 - loss: 0.2737 - acc: 0.899 - ETA: 1:39 - loss: 0.2735 - acc: 0.899 - ETA: 1:39 - loss: 0.2732 - acc: 0.899 - ETA: 1:38 - loss: 0.2734 - acc: 0.899 - ETA: 1:37 - loss: 0.2730 - acc: 0.899 - ETA: 1:37 - loss: 0.2727 - acc: 0.899 - ETA: 1:37 - loss: 0.2725 - acc: 0.899 - ETA: 1:36 - loss: 0.2735 - acc: 0.899 - ETA: 1:36 - loss: 0.2735 - acc: 0.899 - ETA: 1:36 - loss: 0.2732 - acc: 0.899 - ETA: 1:35 - loss: 0.2732 - acc: 0.899 - ETA: 1:35 - loss: 0.2730 - acc: 0.899 - ETA: 1:34 - loss: 0.2732 - acc: 0.899 - ETA: 1:33 - loss: 0.2737 - acc: 0.8994"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23750/23750 [==============================] - ETA: 1:33 - loss: 0.2736 - acc: 0.899 - ETA: 1:32 - loss: 0.2741 - acc: 0.899 - ETA: 1:32 - loss: 0.2741 - acc: 0.899 - ETA: 1:31 - loss: 0.2742 - acc: 0.899 - ETA: 1:30 - loss: 0.2740 - acc: 0.899 - ETA: 1:30 - loss: 0.2741 - acc: 0.899 - ETA: 1:29 - loss: 0.2739 - acc: 0.899 - ETA: 1:28 - loss: 0.2737 - acc: 0.899 - ETA: 1:28 - loss: 0.2743 - acc: 0.899 - ETA: 1:27 - loss: 0.2737 - acc: 0.899 - ETA: 1:27 - loss: 0.2735 - acc: 0.899 - ETA: 1:26 - loss: 0.2733 - acc: 0.899 - ETA: 1:25 - loss: 0.2734 - acc: 0.899 - ETA: 1:25 - loss: 0.2733 - acc: 0.899 - ETA: 1:24 - loss: 0.2737 - acc: 0.899 - ETA: 1:24 - loss: 0.2742 - acc: 0.899 - ETA: 1:23 - loss: 0.2736 - acc: 0.899 - ETA: 1:22 - loss: 0.2739 - acc: 0.899 - ETA: 1:22 - loss: 0.2736 - acc: 0.899 - ETA: 1:21 - loss: 0.2738 - acc: 0.899 - ETA: 1:20 - loss: 0.2734 - acc: 0.899 - ETA: 1:20 - loss: 0.2738 - acc: 0.898 - ETA: 1:19 - loss: 0.2735 - acc: 0.899 - ETA: 1:19 - loss: 0.2732 - acc: 0.899 - ETA: 1:18 - loss: 0.2730 - acc: 0.899 - ETA: 1:17 - loss: 0.2730 - acc: 0.899 - ETA: 1:17 - loss: 0.2729 - acc: 0.899 - ETA: 1:16 - loss: 0.2726 - acc: 0.899 - ETA: 1:16 - loss: 0.2725 - acc: 0.899 - ETA: 1:15 - loss: 0.2734 - acc: 0.899 - ETA: 1:14 - loss: 0.2735 - acc: 0.899 - ETA: 1:14 - loss: 0.2739 - acc: 0.898 - ETA: 1:13 - loss: 0.2743 - acc: 0.898 - ETA: 1:13 - loss: 0.2746 - acc: 0.898 - ETA: 1:12 - loss: 0.2749 - acc: 0.898 - ETA: 1:11 - loss: 0.2751 - acc: 0.898 - ETA: 1:11 - loss: 0.2756 - acc: 0.898 - ETA: 1:10 - loss: 0.2758 - acc: 0.898 - ETA: 1:10 - loss: 0.2758 - acc: 0.898 - ETA: 1:09 - loss: 0.2757 - acc: 0.898 - ETA: 1:09 - loss: 0.2759 - acc: 0.898 - ETA: 1:08 - loss: 0.2761 - acc: 0.898 - ETA: 1:07 - loss: 0.2762 - acc: 0.897 - ETA: 1:07 - loss: 0.2763 - acc: 0.897 - ETA: 1:06 - loss: 0.2761 - acc: 0.897 - ETA: 1:06 - loss: 0.2763 - acc: 0.897 - ETA: 1:05 - loss: 0.2761 - acc: 0.897 - ETA: 1:05 - loss: 0.2758 - acc: 0.898 - ETA: 1:04 - loss: 0.2754 - acc: 0.898 - ETA: 1:03 - loss: 0.2751 - acc: 0.898 - ETA: 1:03 - loss: 0.2750 - acc: 0.898 - ETA: 1:02 - loss: 0.2749 - acc: 0.898 - ETA: 1:02 - loss: 0.2754 - acc: 0.898 - ETA: 1:01 - loss: 0.2755 - acc: 0.898 - ETA: 1:01 - loss: 0.2754 - acc: 0.898 - ETA: 1:01 - loss: 0.2757 - acc: 0.897 - ETA: 1:00 - loss: 0.2757 - acc: 0.898 - ETA: 1:00 - loss: 0.2755 - acc: 0.898 - ETA: 59s - loss: 0.2755 - acc: 0.898 - ETA: 59s - loss: 0.2754 - acc: 0.89 - ETA: 58s - loss: 0.2753 - acc: 0.89 - ETA: 58s - loss: 0.2758 - acc: 0.89 - ETA: 57s - loss: 0.2757 - acc: 0.89 - ETA: 57s - loss: 0.2757 - acc: 0.89 - ETA: 56s - loss: 0.2756 - acc: 0.89 - ETA: 56s - loss: 0.2754 - acc: 0.89 - ETA: 55s - loss: 0.2749 - acc: 0.89 - ETA: 55s - loss: 0.2746 - acc: 0.89 - ETA: 54s - loss: 0.2740 - acc: 0.89 - ETA: 53s - loss: 0.2737 - acc: 0.89 - ETA: 53s - loss: 0.2736 - acc: 0.89 - ETA: 53s - loss: 0.2733 - acc: 0.89 - ETA: 52s - loss: 0.2737 - acc: 0.89 - ETA: 52s - loss: 0.2742 - acc: 0.89 - ETA: 51s - loss: 0.2745 - acc: 0.89 - ETA: 51s - loss: 0.2747 - acc: 0.89 - ETA: 50s - loss: 0.2750 - acc: 0.89 - ETA: 49s - loss: 0.2748 - acc: 0.89 - ETA: 49s - loss: 0.2745 - acc: 0.89 - ETA: 48s - loss: 0.2746 - acc: 0.89 - ETA: 48s - loss: 0.2742 - acc: 0.89 - ETA: 47s - loss: 0.2741 - acc: 0.89 - ETA: 47s - loss: 0.2740 - acc: 0.89 - ETA: 46s - loss: 0.2737 - acc: 0.89 - ETA: 45s - loss: 0.2736 - acc: 0.89 - ETA: 45s - loss: 0.2736 - acc: 0.89 - ETA: 44s - loss: 0.2733 - acc: 0.89 - ETA: 44s - loss: 0.2738 - acc: 0.89 - ETA: 43s - loss: 0.2739 - acc: 0.89 - ETA: 43s - loss: 0.2740 - acc: 0.89 - ETA: 42s - loss: 0.2742 - acc: 0.89 - ETA: 41s - loss: 0.2743 - acc: 0.89 - ETA: 41s - loss: 0.2744 - acc: 0.89 - ETA: 40s - loss: 0.2741 - acc: 0.89 - ETA: 40s - loss: 0.2739 - acc: 0.89 - ETA: 39s - loss: 0.2739 - acc: 0.89 - ETA: 39s - loss: 0.2740 - acc: 0.89 - ETA: 38s - loss: 0.2743 - acc: 0.89 - ETA: 37s - loss: 0.2743 - acc: 0.89 - ETA: 37s - loss: 0.2740 - acc: 0.89 - ETA: 36s - loss: 0.2738 - acc: 0.89 - ETA: 36s - loss: 0.2739 - acc: 0.89 - ETA: 35s - loss: 0.2741 - acc: 0.89 - ETA: 35s - loss: 0.2743 - acc: 0.89 - ETA: 34s - loss: 0.2740 - acc: 0.89 - ETA: 33s - loss: 0.2740 - acc: 0.89 - ETA: 33s - loss: 0.2738 - acc: 0.89 - ETA: 32s - loss: 0.2738 - acc: 0.89 - ETA: 32s - loss: 0.2736 - acc: 0.89 - ETA: 31s - loss: 0.2735 - acc: 0.89 - ETA: 31s - loss: 0.2732 - acc: 0.89 - ETA: 30s - loss: 0.2732 - acc: 0.89 - ETA: 29s - loss: 0.2735 - acc: 0.89 - ETA: 29s - loss: 0.2737 - acc: 0.89 - ETA: 28s - loss: 0.2735 - acc: 0.89 - ETA: 28s - loss: 0.2735 - acc: 0.89 - ETA: 27s - loss: 0.2735 - acc: 0.89 - ETA: 27s - loss: 0.2737 - acc: 0.89 - ETA: 26s - loss: 0.2734 - acc: 0.89 - ETA: 26s - loss: 0.2731 - acc: 0.89 - ETA: 25s - loss: 0.2732 - acc: 0.89 - ETA: 25s - loss: 0.2733 - acc: 0.89 - ETA: 24s - loss: 0.2732 - acc: 0.89 - ETA: 24s - loss: 0.2729 - acc: 0.89 - ETA: 23s - loss: 0.2731 - acc: 0.89 - ETA: 23s - loss: 0.2733 - acc: 0.89 - ETA: 22s - loss: 0.2731 - acc: 0.89 - ETA: 22s - loss: 0.2731 - acc: 0.89 - ETA: 21s - loss: 0.2731 - acc: 0.89 - ETA: 21s - loss: 0.2733 - acc: 0.89 - ETA: 20s - loss: 0.2732 - acc: 0.89 - ETA: 20s - loss: 0.2728 - acc: 0.89 - ETA: 19s - loss: 0.2728 - acc: 0.89 - ETA: 18s - loss: 0.2729 - acc: 0.89 - ETA: 18s - loss: 0.2730 - acc: 0.89 - ETA: 17s - loss: 0.2728 - acc: 0.89 - ETA: 17s - loss: 0.2726 - acc: 0.89 - ETA: 16s - loss: 0.2724 - acc: 0.89 - ETA: 16s - loss: 0.2727 - acc: 0.89 - ETA: 15s - loss: 0.2726 - acc: 0.89 - ETA: 15s - loss: 0.2728 - acc: 0.89 - ETA: 14s - loss: 0.2728 - acc: 0.89 - ETA: 13s - loss: 0.2725 - acc: 0.89 - ETA: 13s - loss: 0.2725 - acc: 0.89 - ETA: 12s - loss: 0.2726 - acc: 0.89 - ETA: 12s - loss: 0.2726 - acc: 0.89 - ETA: 11s - loss: 0.2726 - acc: 0.89 - ETA: 11s - loss: 0.2722 - acc: 0.89 - ETA: 10s - loss: 0.2719 - acc: 0.89 - ETA: 9s - loss: 0.2719 - acc: 0.8986 - ETA: 9s - loss: 0.2725 - acc: 0.898 - ETA: 8s - loss: 0.2726 - acc: 0.898 - ETA: 8s - loss: 0.2730 - acc: 0.898 - ETA: 7s - loss: 0.2728 - acc: 0.898 - ETA: 7s - loss: 0.2728 - acc: 0.898 - ETA: 6s - loss: 0.2731 - acc: 0.898 - ETA: 6s - loss: 0.2730 - acc: 0.897 - ETA: 5s - loss: 0.2732 - acc: 0.897 - ETA: 4s - loss: 0.2734 - acc: 0.897 - ETA: 4s - loss: 0.2731 - acc: 0.897 - ETA: 3s - loss: 0.2732 - acc: 0.897 - ETA: 3s - loss: 0.2732 - acc: 0.897 - ETA: 2s - loss: 0.2732 - acc: 0.897 - ETA: 1s - loss: 0.2731 - acc: 0.897 - ETA: 1s - loss: 0.2729 - acc: 0.898 - ETA: 0s - loss: 0.2729 - acc: 0.898 - ETA: 0s - loss: 0.2729 - acc: 0.898 - 230s 10ms/step - loss: 0.2729 - acc: 0.8980 - val_loss: 0.2200 - val_acc: 0.9168\n",
      "Epoch 3/3\n",
      "13056/23750 [===============>..............] - ETA: 3:55 - loss: 0.2454 - acc: 0.890 - ETA: 3:30 - loss: 0.1725 - acc: 0.937 - ETA: 3:19 - loss: 0.2053 - acc: 0.927 - ETA: 3:14 - loss: 0.2007 - acc: 0.933 - ETA: 3:21 - loss: 0.2078 - acc: 0.925 - ETA: 3:21 - loss: 0.2361 - acc: 0.906 - ETA: 3:17 - loss: 0.2342 - acc: 0.906 - ETA: 3:14 - loss: 0.2305 - acc: 0.906 - ETA: 3:12 - loss: 0.2274 - acc: 0.911 - ETA: 3:09 - loss: 0.2217 - acc: 0.915 - ETA: 3:10 - loss: 0.2128 - acc: 0.920 - ETA: 3:10 - loss: 0.2185 - acc: 0.919 - ETA: 3:09 - loss: 0.2212 - acc: 0.918 - ETA: 3:08 - loss: 0.2186 - acc: 0.918 - ETA: 3:06 - loss: 0.2119 - acc: 0.920 - ETA: 3:07 - loss: 0.2144 - acc: 0.921 - ETA: 3:06 - loss: 0.2143 - acc: 0.922 - ETA: 3:05 - loss: 0.2159 - acc: 0.921 - ETA: 3:04 - loss: 0.2192 - acc: 0.920 - ETA: 3:03 - loss: 0.2157 - acc: 0.922 - ETA: 3:02 - loss: 0.2121 - acc: 0.924 - ETA: 3:01 - loss: 0.2100 - acc: 0.925 - ETA: 3:00 - loss: 0.2139 - acc: 0.924 - ETA: 2:59 - loss: 0.2142 - acc: 0.925 - ETA: 2:58 - loss: 0.2111 - acc: 0.926 - ETA: 2:58 - loss: 0.2112 - acc: 0.925 - ETA: 2:57 - loss: 0.2072 - acc: 0.927 - ETA: 2:56 - loss: 0.2063 - acc: 0.927 - ETA: 2:55 - loss: 0.2077 - acc: 0.927 - ETA: 2:54 - loss: 0.2064 - acc: 0.927 - ETA: 2:53 - loss: 0.2087 - acc: 0.926 - ETA: 2:53 - loss: 0.2108 - acc: 0.926 - ETA: 2:52 - loss: 0.2083 - acc: 0.927 - ETA: 2:51 - loss: 0.2077 - acc: 0.927 - ETA: 2:50 - loss: 0.2098 - acc: 0.926 - ETA: 2:50 - loss: 0.2088 - acc: 0.927 - ETA: 2:49 - loss: 0.2090 - acc: 0.927 - ETA: 2:48 - loss: 0.2086 - acc: 0.927 - ETA: 2:48 - loss: 0.2097 - acc: 0.927 - ETA: 2:47 - loss: 0.2117 - acc: 0.926 - ETA: 2:47 - loss: 0.2116 - acc: 0.925 - ETA: 2:46 - loss: 0.2119 - acc: 0.925 - ETA: 2:46 - loss: 0.2111 - acc: 0.925 - ETA: 2:45 - loss: 0.2130 - acc: 0.924 - ETA: 2:44 - loss: 0.2170 - acc: 0.923 - ETA: 2:44 - loss: 0.2179 - acc: 0.922 - ETA: 2:43 - loss: 0.2163 - acc: 0.923 - ETA: 2:42 - loss: 0.2147 - acc: 0.924 - ETA: 2:42 - loss: 0.2143 - acc: 0.925 - ETA: 2:41 - loss: 0.2128 - acc: 0.925 - ETA: 2:41 - loss: 0.2102 - acc: 0.926 - ETA: 2:40 - loss: 0.2089 - acc: 0.926 - ETA: 2:39 - loss: 0.2112 - acc: 0.926 - ETA: 2:39 - loss: 0.2104 - acc: 0.926 - ETA: 2:38 - loss: 0.2108 - acc: 0.926 - ETA: 2:38 - loss: 0.2113 - acc: 0.926 - ETA: 2:37 - loss: 0.2115 - acc: 0.926 - ETA: 2:36 - loss: 0.2094 - acc: 0.927 - ETA: 2:36 - loss: 0.2085 - acc: 0.927 - ETA: 2:35 - loss: 0.2077 - acc: 0.927 - ETA: 2:35 - loss: 0.2087 - acc: 0.927 - ETA: 2:34 - loss: 0.2095 - acc: 0.927 - ETA: 2:33 - loss: 0.2103 - acc: 0.927 - ETA: 2:33 - loss: 0.2088 - acc: 0.927 - ETA: 2:33 - loss: 0.2075 - acc: 0.928 - ETA: 2:32 - loss: 0.2065 - acc: 0.928 - ETA: 2:32 - loss: 0.2080 - acc: 0.928 - ETA: 2:31 - loss: 0.2074 - acc: 0.928 - ETA: 2:30 - loss: 0.2076 - acc: 0.928 - ETA: 2:30 - loss: 0.2090 - acc: 0.928 - ETA: 2:29 - loss: 0.2100 - acc: 0.928 - ETA: 2:28 - loss: 0.2101 - acc: 0.928 - ETA: 2:28 - loss: 0.2095 - acc: 0.928 - ETA: 2:27 - loss: 0.2088 - acc: 0.929 - ETA: 2:27 - loss: 0.2096 - acc: 0.928 - ETA: 2:26 - loss: 0.2080 - acc: 0.929 - ETA: 2:25 - loss: 0.2091 - acc: 0.929 - ETA: 2:25 - loss: 0.2080 - acc: 0.929 - ETA: 2:24 - loss: 0.2082 - acc: 0.929 - ETA: 2:24 - loss: 0.2086 - acc: 0.929 - ETA: 2:23 - loss: 0.2098 - acc: 0.929 - ETA: 2:22 - loss: 0.2108 - acc: 0.928 - ETA: 2:22 - loss: 0.2098 - acc: 0.929 - ETA: 2:21 - loss: 0.2112 - acc: 0.928 - ETA: 2:21 - loss: 0.2109 - acc: 0.928 - ETA: 2:20 - loss: 0.2096 - acc: 0.929 - ETA: 2:19 - loss: 0.2095 - acc: 0.929 - ETA: 2:19 - loss: 0.2090 - acc: 0.929 - ETA: 2:18 - loss: 0.2091 - acc: 0.929 - ETA: 2:18 - loss: 0.2084 - acc: 0.929 - ETA: 2:17 - loss: 0.2069 - acc: 0.930 - ETA: 2:17 - loss: 0.2080 - acc: 0.929 - ETA: 2:16 - loss: 0.2094 - acc: 0.928 - ETA: 2:16 - loss: 0.2094 - acc: 0.929 - ETA: 2:15 - loss: 0.2110 - acc: 0.928 - ETA: 2:14 - loss: 0.2100 - acc: 0.928 - ETA: 2:14 - loss: 0.2099 - acc: 0.928 - ETA: 2:13 - loss: 0.2094 - acc: 0.929 - ETA: 2:13 - loss: 0.2105 - acc: 0.928 - ETA: 2:12 - loss: 0.2098 - acc: 0.928 - ETA: 2:12 - loss: 0.2097 - acc: 0.928 - ETA: 2:11 - loss: 0.2087 - acc: 0.929 - ETA: 2:10 - loss: 0.2091 - acc: 0.929 - ETA: 2:10 - loss: 0.2085 - acc: 0.929 - ETA: 2:09 - loss: 0.2077 - acc: 0.929 - ETA: 2:09 - loss: 0.2075 - acc: 0.929 - ETA: 2:08 - loss: 0.2078 - acc: 0.929 - ETA: 2:08 - loss: 0.2080 - acc: 0.929 - ETA: 2:07 - loss: 0.2080 - acc: 0.929 - ETA: 2:07 - loss: 0.2082 - acc: 0.929 - ETA: 2:06 - loss: 0.2085 - acc: 0.929 - ETA: 2:06 - loss: 0.2084 - acc: 0.929 - ETA: 2:05 - loss: 0.2078 - acc: 0.929 - ETA: 2:04 - loss: 0.2082 - acc: 0.928 - ETA: 2:04 - loss: 0.2082 - acc: 0.928 - ETA: 2:03 - loss: 0.2082 - acc: 0.928 - ETA: 2:03 - loss: 0.2081 - acc: 0.929 - ETA: 2:02 - loss: 0.2088 - acc: 0.928 - ETA: 2:02 - loss: 0.2090 - acc: 0.928 - ETA: 2:01 - loss: 0.2091 - acc: 0.928 - ETA: 2:01 - loss: 0.2085 - acc: 0.928 - ETA: 2:00 - loss: 0.2086 - acc: 0.928 - ETA: 2:00 - loss: 0.2092 - acc: 0.928 - ETA: 1:59 - loss: 0.2092 - acc: 0.928 - ETA: 1:59 - loss: 0.2093 - acc: 0.928 - ETA: 1:58 - loss: 0.2088 - acc: 0.928 - ETA: 1:58 - loss: 0.2098 - acc: 0.928 - ETA: 1:57 - loss: 0.2098 - acc: 0.928 - ETA: 1:57 - loss: 0.2101 - acc: 0.927 - ETA: 1:56 - loss: 0.2100 - acc: 0.927 - ETA: 1:56 - loss: 0.2098 - acc: 0.927 - ETA: 1:55 - loss: 0.2095 - acc: 0.927 - ETA: 1:54 - loss: 0.2089 - acc: 0.928 - ETA: 1:54 - loss: 0.2083 - acc: 0.928 - ETA: 1:53 - loss: 0.2089 - acc: 0.927 - ETA: 1:53 - loss: 0.2090 - acc: 0.927 - ETA: 1:52 - loss: 0.2093 - acc: 0.927 - ETA: 1:52 - loss: 0.2092 - acc: 0.927 - ETA: 1:51 - loss: 0.2089 - acc: 0.927 - ETA: 1:51 - loss: 0.2082 - acc: 0.927 - ETA: 1:50 - loss: 0.2077 - acc: 0.928 - ETA: 1:50 - loss: 0.2075 - acc: 0.928 - ETA: 1:49 - loss: 0.2080 - acc: 0.928 - ETA: 1:49 - loss: 0.2087 - acc: 0.927 - ETA: 1:48 - loss: 0.2087 - acc: 0.927 - ETA: 1:48 - loss: 0.2088 - acc: 0.927 - ETA: 1:47 - loss: 0.2085 - acc: 0.927 - ETA: 1:47 - loss: 0.2084 - acc: 0.927 - ETA: 1:46 - loss: 0.2082 - acc: 0.927 - ETA: 1:46 - loss: 0.2081 - acc: 0.927 - ETA: 1:45 - loss: 0.2089 - acc: 0.927 - ETA: 1:45 - loss: 0.2083 - acc: 0.927 - ETA: 1:44 - loss: 0.2084 - acc: 0.927 - ETA: 1:44 - loss: 0.2080 - acc: 0.927 - ETA: 1:43 - loss: 0.2074 - acc: 0.927 - ETA: 1:43 - loss: 0.2076 - acc: 0.927 - ETA: 1:42 - loss: 0.2076 - acc: 0.927 - ETA: 1:42 - loss: 0.2077 - acc: 0.927 - ETA: 1:41 - loss: 0.2078 - acc: 0.927 - ETA: 1:41 - loss: 0.2074 - acc: 0.927 - ETA: 1:40 - loss: 0.2080 - acc: 0.927 - ETA: 1:40 - loss: 0.2080 - acc: 0.927 - ETA: 1:39 - loss: 0.2083 - acc: 0.927 - ETA: 1:39 - loss: 0.2093 - acc: 0.927 - ETA: 1:38 - loss: 0.2096 - acc: 0.927 - ETA: 1:38 - loss: 0.2092 - acc: 0.927 - ETA: 1:37 - loss: 0.2097 - acc: 0.927 - ETA: 1:37 - loss: 0.2092 - acc: 0.927 - ETA: 1:36 - loss: 0.2087 - acc: 0.927 - ETA: 1:36 - loss: 0.2083 - acc: 0.927 - ETA: 1:35 - loss: 0.2078 - acc: 0.927 - ETA: 1:35 - loss: 0.2074 - acc: 0.928 - ETA: 1:34 - loss: 0.2070 - acc: 0.928 - ETA: 1:34 - loss: 0.2070 - acc: 0.928 - ETA: 1:34 - loss: 0.2072 - acc: 0.928 - ETA: 1:34 - loss: 0.2072 - acc: 0.928 - ETA: 1:34 - loss: 0.2068 - acc: 0.928 - ETA: 1:34 - loss: 0.2067 - acc: 0.928 - ETA: 1:34 - loss: 0.2061 - acc: 0.928 - ETA: 1:34 - loss: 0.2060 - acc: 0.928 - ETA: 1:34 - loss: 0.2064 - acc: 0.928 - ETA: 1:34 - loss: 0.2059 - acc: 0.928 - ETA: 1:34 - loss: 0.2062 - acc: 0.928 - ETA: 1:33 - loss: 0.2064 - acc: 0.928 - ETA: 1:33 - loss: 0.2064 - acc: 0.928 - ETA: 1:33 - loss: 0.2066 - acc: 0.928 - ETA: 1:33 - loss: 0.2070 - acc: 0.927 - ETA: 1:33 - loss: 0.2073 - acc: 0.927 - ETA: 1:33 - loss: 0.2069 - acc: 0.928 - ETA: 1:33 - loss: 0.2065 - acc: 0.928 - ETA: 1:32 - loss: 0.2063 - acc: 0.928 - ETA: 1:32 - loss: 0.2068 - acc: 0.928 - ETA: 1:32 - loss: 0.2064 - acc: 0.928 - ETA: 1:32 - loss: 0.2066 - acc: 0.928 - ETA: 1:32 - loss: 0.2062 - acc: 0.928 - ETA: 1:31 - loss: 0.2055 - acc: 0.928 - ETA: 1:31 - loss: 0.2057 - acc: 0.928 - ETA: 1:31 - loss: 0.2053 - acc: 0.928 - ETA: 1:31 - loss: 0.2052 - acc: 0.928 - ETA: 1:30 - loss: 0.2050 - acc: 0.928 - ETA: 1:30 - loss: 0.2055 - acc: 0.928 - ETA: 1:30 - loss: 0.2053 - acc: 0.928 - ETA: 1:30 - loss: 0.2049 - acc: 0.929 - ETA: 1:29 - loss: 0.2050 - acc: 0.928823750/23750 [==============================] - ETA: 1:29 - loss: 0.2051 - acc: 0.928 - ETA: 1:29 - loss: 0.2048 - acc: 0.928 - ETA: 1:29 - loss: 0.2046 - acc: 0.928 - ETA: 1:28 - loss: 0.2049 - acc: 0.928 - ETA: 1:28 - loss: 0.2052 - acc: 0.928 - ETA: 1:28 - loss: 0.2054 - acc: 0.928 - ETA: 1:27 - loss: 0.2050 - acc: 0.928 - ETA: 1:27 - loss: 0.2052 - acc: 0.928 - ETA: 1:27 - loss: 0.2050 - acc: 0.928 - ETA: 1:27 - loss: 0.2054 - acc: 0.928 - ETA: 1:26 - loss: 0.2053 - acc: 0.928 - ETA: 1:26 - loss: 0.2048 - acc: 0.928 - ETA: 1:26 - loss: 0.2051 - acc: 0.928 - ETA: 1:25 - loss: 0.2053 - acc: 0.928 - ETA: 1:25 - loss: 0.2053 - acc: 0.928 - ETA: 1:25 - loss: 0.2056 - acc: 0.928 - ETA: 1:24 - loss: 0.2062 - acc: 0.928 - ETA: 1:24 - loss: 0.2063 - acc: 0.928 - ETA: 1:23 - loss: 0.2062 - acc: 0.928 - ETA: 1:23 - loss: 0.2061 - acc: 0.927 - ETA: 1:23 - loss: 0.2058 - acc: 0.928 - ETA: 1:22 - loss: 0.2058 - acc: 0.928 - ETA: 1:22 - loss: 0.2059 - acc: 0.927 - ETA: 1:22 - loss: 0.2062 - acc: 0.927 - ETA: 1:21 - loss: 0.2063 - acc: 0.927 - ETA: 1:21 - loss: 0.2064 - acc: 0.927 - ETA: 1:20 - loss: 0.2064 - acc: 0.927 - ETA: 1:20 - loss: 0.2066 - acc: 0.927 - ETA: 1:20 - loss: 0.2071 - acc: 0.927 - ETA: 1:19 - loss: 0.2072 - acc: 0.927 - ETA: 1:19 - loss: 0.2074 - acc: 0.927 - ETA: 1:19 - loss: 0.2076 - acc: 0.926 - ETA: 1:18 - loss: 0.2076 - acc: 0.926 - ETA: 1:18 - loss: 0.2078 - acc: 0.926 - ETA: 1:17 - loss: 0.2077 - acc: 0.926 - ETA: 1:17 - loss: 0.2080 - acc: 0.926 - ETA: 1:16 - loss: 0.2085 - acc: 0.926 - ETA: 1:16 - loss: 0.2083 - acc: 0.926 - ETA: 1:15 - loss: 0.2084 - acc: 0.926 - ETA: 1:15 - loss: 0.2082 - acc: 0.926 - ETA: 1:15 - loss: 0.2083 - acc: 0.926 - ETA: 1:14 - loss: 0.2086 - acc: 0.926 - ETA: 1:14 - loss: 0.2086 - acc: 0.926 - ETA: 1:13 - loss: 0.2082 - acc: 0.926 - ETA: 1:13 - loss: 0.2081 - acc: 0.926 - ETA: 1:12 - loss: 0.2084 - acc: 0.926 - ETA: 1:12 - loss: 0.2089 - acc: 0.926 - ETA: 1:12 - loss: 0.2088 - acc: 0.926 - ETA: 1:11 - loss: 0.2088 - acc: 0.926 - ETA: 1:11 - loss: 0.2087 - acc: 0.926 - ETA: 1:10 - loss: 0.2084 - acc: 0.926 - ETA: 1:10 - loss: 0.2085 - acc: 0.926 - ETA: 1:09 - loss: 0.2083 - acc: 0.926 - ETA: 1:09 - loss: 0.2082 - acc: 0.926 - ETA: 1:08 - loss: 0.2082 - acc: 0.926 - ETA: 1:08 - loss: 0.2086 - acc: 0.926 - ETA: 1:07 - loss: 0.2086 - acc: 0.926 - ETA: 1:07 - loss: 0.2087 - acc: 0.926 - ETA: 1:06 - loss: 0.2083 - acc: 0.926 - ETA: 1:06 - loss: 0.2082 - acc: 0.926 - ETA: 1:05 - loss: 0.2081 - acc: 0.926 - ETA: 1:05 - loss: 0.2081 - acc: 0.926 - ETA: 1:04 - loss: 0.2081 - acc: 0.926 - ETA: 1:04 - loss: 0.2079 - acc: 0.926 - ETA: 1:03 - loss: 0.2081 - acc: 0.926 - ETA: 1:03 - loss: 0.2078 - acc: 0.926 - ETA: 1:02 - loss: 0.2074 - acc: 0.926 - ETA: 1:02 - loss: 0.2072 - acc: 0.927 - ETA: 1:01 - loss: 0.2071 - acc: 0.927 - ETA: 1:01 - loss: 0.2069 - acc: 0.927 - ETA: 1:00 - loss: 0.2071 - acc: 0.927 - ETA: 1:00 - loss: 0.2072 - acc: 0.927 - ETA: 59s - loss: 0.2073 - acc: 0.927 - ETA: 59s - loss: 0.2072 - acc: 0.92 - ETA: 58s - loss: 0.2070 - acc: 0.92 - ETA: 58s - loss: 0.2071 - acc: 0.92 - ETA: 57s - loss: 0.2074 - acc: 0.92 - ETA: 57s - loss: 0.2072 - acc: 0.92 - ETA: 56s - loss: 0.2072 - acc: 0.92 - ETA: 56s - loss: 0.2071 - acc: 0.92 - ETA: 55s - loss: 0.2070 - acc: 0.92 - ETA: 54s - loss: 0.2074 - acc: 0.92 - ETA: 54s - loss: 0.2075 - acc: 0.92 - ETA: 53s - loss: 0.2076 - acc: 0.92 - ETA: 53s - loss: 0.2074 - acc: 0.92 - ETA: 52s - loss: 0.2071 - acc: 0.92 - ETA: 51s - loss: 0.2069 - acc: 0.92 - ETA: 51s - loss: 0.2070 - acc: 0.92 - ETA: 50s - loss: 0.2073 - acc: 0.92 - ETA: 50s - loss: 0.2074 - acc: 0.92 - ETA: 49s - loss: 0.2078 - acc: 0.92 - ETA: 49s - loss: 0.2078 - acc: 0.92 - ETA: 48s - loss: 0.2075 - acc: 0.92 - ETA: 47s - loss: 0.2073 - acc: 0.92 - ETA: 47s - loss: 0.2073 - acc: 0.92 - ETA: 46s - loss: 0.2074 - acc: 0.92 - ETA: 45s - loss: 0.2077 - acc: 0.92 - ETA: 45s - loss: 0.2075 - acc: 0.92 - ETA: 44s - loss: 0.2074 - acc: 0.92 - ETA: 44s - loss: 0.2078 - acc: 0.92 - ETA: 43s - loss: 0.2077 - acc: 0.92 - ETA: 42s - loss: 0.2076 - acc: 0.92 - ETA: 42s - loss: 0.2074 - acc: 0.92 - ETA: 41s - loss: 0.2079 - acc: 0.92 - ETA: 41s - loss: 0.2079 - acc: 0.92 - ETA: 40s - loss: 0.2078 - acc: 0.92 - ETA: 39s - loss: 0.2078 - acc: 0.92 - ETA: 39s - loss: 0.2077 - acc: 0.92 - ETA: 38s - loss: 0.2076 - acc: 0.92 - ETA: 37s - loss: 0.2077 - acc: 0.92 - ETA: 37s - loss: 0.2076 - acc: 0.92 - ETA: 36s - loss: 0.2078 - acc: 0.92 - ETA: 36s - loss: 0.2082 - acc: 0.92 - ETA: 35s - loss: 0.2080 - acc: 0.92 - ETA: 34s - loss: 0.2085 - acc: 0.92 - ETA: 34s - loss: 0.2084 - acc: 0.92 - ETA: 33s - loss: 0.2084 - acc: 0.92 - ETA: 32s - loss: 0.2085 - acc: 0.92 - ETA: 32s - loss: 0.2086 - acc: 0.92 - ETA: 31s - loss: 0.2086 - acc: 0.92 - ETA: 30s - loss: 0.2085 - acc: 0.92 - ETA: 30s - loss: 0.2086 - acc: 0.92 - ETA: 29s - loss: 0.2091 - acc: 0.92 - ETA: 29s - loss: 0.2090 - acc: 0.92 - ETA: 28s - loss: 0.2093 - acc: 0.92 - ETA: 27s - loss: 0.2091 - acc: 0.92 - ETA: 27s - loss: 0.2087 - acc: 0.92 - ETA: 26s - loss: 0.2089 - acc: 0.92 - ETA: 25s - loss: 0.2091 - acc: 0.92 - ETA: 25s - loss: 0.2090 - acc: 0.92 - ETA: 24s - loss: 0.2089 - acc: 0.92 - ETA: 23s - loss: 0.2086 - acc: 0.92 - ETA: 23s - loss: 0.2089 - acc: 0.92 - ETA: 22s - loss: 0.2089 - acc: 0.92 - ETA: 21s - loss: 0.2088 - acc: 0.92 - ETA: 21s - loss: 0.2086 - acc: 0.92 - ETA: 20s - loss: 0.2086 - acc: 0.92 - ETA: 19s - loss: 0.2087 - acc: 0.92 - ETA: 19s - loss: 0.2087 - acc: 0.92 - ETA: 18s - loss: 0.2091 - acc: 0.92 - ETA: 17s - loss: 0.2089 - acc: 0.92 - ETA: 17s - loss: 0.2090 - acc: 0.92 - ETA: 16s - loss: 0.2092 - acc: 0.92 - ETA: 15s - loss: 0.2093 - acc: 0.92 - ETA: 15s - loss: 0.2092 - acc: 0.92 - ETA: 14s - loss: 0.2092 - acc: 0.92 - ETA: 13s - loss: 0.2095 - acc: 0.92 - ETA: 13s - loss: 0.2097 - acc: 0.92 - ETA: 12s - loss: 0.2098 - acc: 0.92 - ETA: 11s - loss: 0.2101 - acc: 0.92 - ETA: 11s - loss: 0.2104 - acc: 0.92 - ETA: 10s - loss: 0.2101 - acc: 0.92 - ETA: 9s - loss: 0.2099 - acc: 0.9258 - ETA: 9s - loss: 0.2100 - acc: 0.925 - ETA: 8s - loss: 0.2097 - acc: 0.926 - ETA: 7s - loss: 0.2094 - acc: 0.926 - ETA: 6s - loss: 0.2092 - acc: 0.926 - ETA: 6s - loss: 0.2089 - acc: 0.926 - ETA: 5s - loss: 0.2087 - acc: 0.926 - ETA: 4s - loss: 0.2088 - acc: 0.926 - ETA: 4s - loss: 0.2088 - acc: 0.926 - ETA: 3s - loss: 0.2089 - acc: 0.926 - ETA: 2s - loss: 0.2093 - acc: 0.926 - ETA: 2s - loss: 0.2094 - acc: 0.926 - ETA: 1s - loss: 0.2098 - acc: 0.926 - ETA: 0s - loss: 0.2099 - acc: 0.926 - ETA: 0s - loss: 0.2098 - acc: 0.925 - 262s 11ms/step - loss: 0.2098 - acc: 0.9259 - val_loss: 0.4118 - val_acc: 0.8176\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25b0a497cc0>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_pad,y_train,validation_split = 0.05,epochs = 3,batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 59s - ETA: 59 - ETA: 59 - ETA: 59 - ETA: 59 - ETA: 59 - ETA: 59 - ETA: 59 - ETA: 58 - ETA: 58 - ETA: 58 - ETA: 58 - ETA: 58 - ETA: 58 - ETA: 58 - ETA: 58 - ETA: 57 - ETA: 57 - ETA: 57 - ETA: 57 - ETA: 57 - ETA: 57 - ETA: 57 - ETA: 57 - ETA: 57 - ETA: 57 - ETA: 57 - ETA: 57 - ETA: 56 - ETA: 56 - ETA: 56 - ETA: 56 - ETA: 56 - ETA: 56 - ETA: 56 - ETA: 56 - ETA: 56 - ETA: 56 - ETA: 55 - ETA: 55 - ETA: 55 - ETA: 55 - ETA: 55 - ETA: 55 - ETA: 55 - ETA: 55 - ETA: 55 - ETA: 54 - ETA: 54 - ETA: 54 - ETA: 54 - ETA: 54 - ETA: 54 - ETA: 54 - ETA: 54 - ETA: 54 - ETA: 54 - ETA: 54 - ETA: 54 - ETA: 53 - ETA: 53 - ETA: 53 - ETA: 53 - ETA: 53 - ETA: 53 - ETA: 53 - ETA: 53 - ETA: 53 - ETA: 53 - ETA: 53 - ETA: 52 - ETA: 52 - ETA: 52 - ETA: 52 - ETA: 52 - ETA: 52 - ETA: 52 - ETA: 52 - ETA: 52 - ETA: 52 - ETA: 51 - ETA: 51 - ETA: 51 - ETA: 51 - ETA: 51 - ETA: 51 - ETA: 51 - ETA: 51 - ETA: 51 - ETA: 51 - ETA: 51 - ETA: 51 - ETA: 50 - ETA: 50 - ETA: 50 - ETA: 50 - ETA: 50 - ETA: 50 - ETA: 50 - ETA: 50 - ETA: 50 - ETA: 50 - ETA: 50 - ETA: 49 - ETA: 49 - ETA: 49 - ETA: 49 - ETA: 49 - ETA: 49 - ETA: 49 - ETA: 49 - ETA: 49 - ETA: 49 - ETA: 49 - ETA: 48 - ETA: 48 - ETA: 48 - ETA: 48 - ETA: 48 - ETA: 48 - ETA: 48 - ETA: 48 - ETA: 48 - ETA: 48 - ETA: 48 - ETA: 48 - ETA: 47 - ETA: 47 - ETA: 47 - ETA: 47 - ETA: 47 - ETA: 47 - ETA: 47 - ETA: 47 - ETA: 47 - ETA: 47 - ETA: 47 - ETA: 46 - ETA: 46 - ETA: 46 - ETA: 46 - ETA: 46 - ETA: 46 - ETA: 46 - ETA: 46 - ETA: 46 - ETA: 46 - ETA: 46 - ETA: 46 - ETA: 45 - ETA: 45 - ETA: 45 - ETA: 45 - ETA: 45 - ETA: 45 - ETA: 45 - ETA: 45 - ETA: 45 - ETA: 45 - ETA: 45 - ETA: 44 - ETA: 44 - ETA: 44 - ETA: 44 - ETA: 44 - ETA: 44 - ETA: 44 - ETA: 44 - ETA: 44 - ETA: 44 - ETA: 44 - ETA: 43 - ETA: 43 - ETA: 43 - ETA: 43 - ETA: 43 - ETA: 43 - ETA: 43 - ETA: 43 - ETA: 43 - ETA: 43 - ETA: 43 - ETA: 43 - ETA: 42 - ETA: 42 - ETA: 42 - ETA: 42 - ETA: 42 - ETA: 42 - ETA: 42 - ETA: 42 - ETA: 42 - ETA: 42 - ETA: 42 - ETA: 42 - ETA: 42 - ETA: 41 - ETA: 41 - ETA: 41 - ETA: 41 - ETA: 41 - ETA: 41 - ETA: 41 - ETA: 41 - ETA: 41 - ETA: 41 - ETA: 41 - ETA: 41 - ETA: 41 - ETA: 40 - ETA: 40 - ETA: 40 - ETA: 40 - ETA: 40 - ETA: 40 - ETA: 40 - ETA: 40 - ETA: 40 - ETA: 40 - ETA: 40 - ETA: 40 - ETA: 39 - ETA: 39 - ETA: 39 - ETA: 39 - ETA: 39 - ETA: 39 - ETA: 39 - ETA: 39 - ETA: 39 - ETA: 39 - ETA: 39 - ETA: 39 - ETA: 38 - ETA: 38 - ETA: 38 - ETA: 38 - ETA: 38 - ETA: 38 - ETA: 38 - ETA: 38 - ETA: 38 - ETA: 38 - ETA: 38 - ETA: 38 - ETA: 37 - ETA: 37 - ETA: 37 - ETA: 37 - ETA: 37 - ETA: 37 - ETA: 37 - ETA: 37 - ETA: 37 - ETA: 37 - ETA: 37 - ETA: 37 - ETA: 37 - ETA: 36 - ETA: 36 - ETA: 36 - ETA: 36 - ETA: 36 - ETA: 36 - ETA: 36 - ETA: 36 - ETA: 36 - ETA: 36 - ETA: 36 - ETA: 36 - ETA: 36 - ETA: 35 - ETA: 35 - ETA: 35 - ETA: 35 - ETA: 35 - ETA: 35 - ETA: 35 - ETA: 35 - ETA: 35 - ETA: 35 - ETA: 35 - ETA: 35 - ETA: 34 - ETA: 34 - ETA: 34 - ETA: 34 - ETA: 34 - ETA: 34 - ETA: 34 - ETA: 34 - ETA: 34 - ETA: 34 - ETA: 34 - ETA: 34 - ETA: 34 - ETA: 33 - ETA: 33 - ETA: 33 - ETA: 33 - ETA: 33 - ETA: 33 - ETA: 33 - ETA: 33 - ETA: 33 - ETA: 33 - ETA: 33 - ETA: 33 - ETA: 32 - ETA: 32 - ETA: 32 - ETA: 32 - ETA: 32 - ETA: 32 - ETA: 32 - ETA: 32 - ETA: 32 - ETA: 32 - ETA: 32 - ETA: 32 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 9 - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 65s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test_pad,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is :  85.452 %\n"
     ]
    }
   ],
   "source": [
    "print(\"The accuracy is : \",results[1]*100,'%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
