{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_datapath = 'F:\\\\Library\\\\Analytics Path\\\\Datasets\\\\01_CNN_Eg1\\\\data\\\\train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_datapath = 'F:\\\\Library\\\\Analytics Path\\\\Datasets\\\\01_CNN_Eg1\\\\data\\\\test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator,load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#im = load_img('path_till_image_name',target_size = (224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?ImageDataGenerator.flow_from_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data = ImageDataGenerator(rescale = 1.0/255).flow_from_directory(train_datapath,target_size = (150,150),batch_size = 2,classes = ['cats','bus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train,train_labels = next(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#works without rescale option only\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# plots images with labels within jupyter notebook\n",
    "def plots(ims, figsize=(12,6), rows=1, interp=False, titles=None):\n",
    "    if type(ims[0]) is np.ndarray:\n",
    "        ims = np.array(ims).astype(np.uint8)\n",
    "        if (ims.shape[-1] != 3):\n",
    "            ims = ims.transpose((0,2,3,1))\n",
    "    f = plt.figure(figsize=figsize)\n",
    "    cols = len(ims)//rows if len(ims) % 2 == 0 else len(ims)//rows + 1\n",
    "    for i in range(len(ims)):\n",
    "        sp = f.add_subplot(rows, cols, i+1)\n",
    "        sp.axis('Off')\n",
    "        if titles is not None:\n",
    "            sp.set_title(titles[i], fontsize=16)\n",
    "        plt.imshow(ims[i], interpolation=None if interp else 'none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plots(train,titles = train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAFhCAYAAACCkjfzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x23905b4bf98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 150, 150, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.7019608 , 0.7019608 , 0.7019608 ],\n",
       "        [0.7058824 , 0.7058824 , 0.7058824 ],\n",
       "        [0.70980394, 0.70980394, 0.70980394],\n",
       "        ...,\n",
       "        [0.70980394, 0.70980394, 0.70980394],\n",
       "        [0.70980394, 0.70980394, 0.70980394],\n",
       "        [0.70980394, 0.70980394, 0.70980394]],\n",
       "\n",
       "       [[0.7019608 , 0.7019608 , 0.7019608 ],\n",
       "        [0.7058824 , 0.7058824 , 0.7058824 ],\n",
       "        [0.70980394, 0.70980394, 0.70980394],\n",
       "        ...,\n",
       "        [0.70980394, 0.70980394, 0.70980394],\n",
       "        [0.70980394, 0.70980394, 0.70980394],\n",
       "        [0.70980394, 0.70980394, 0.70980394]],\n",
       "\n",
       "       [[0.7058824 , 0.7058824 , 0.7058824 ],\n",
       "        [0.70980394, 0.70980394, 0.70980394],\n",
       "        [0.7137255 , 0.7137255 , 0.7137255 ],\n",
       "        ...,\n",
       "        [0.7137255 , 0.7137255 , 0.7137255 ],\n",
       "        [0.70980394, 0.70980394, 0.70980394],\n",
       "        [0.70980394, 0.70980394, 0.70980394]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.7058824 , 0.7058824 , 0.7058824 ],\n",
       "        [0.70980394, 0.70980394, 0.70980394],\n",
       "        [0.7176471 , 0.7176471 , 0.7176471 ],\n",
       "        ...,\n",
       "        [0.7137255 , 0.7137255 , 0.7137255 ],\n",
       "        [0.7058824 , 0.7058824 , 0.7058824 ],\n",
       "        [0.7058824 , 0.7058824 , 0.7058824 ]],\n",
       "\n",
       "       [[0.7019608 , 0.7019608 , 0.7019608 ],\n",
       "        [0.7058824 , 0.7058824 , 0.7058824 ],\n",
       "        [0.7137255 , 0.7137255 , 0.7137255 ],\n",
       "        ...,\n",
       "        [0.70980394, 0.70980394, 0.70980394],\n",
       "        [0.7058824 , 0.7058824 , 0.7058824 ],\n",
       "        [0.7058824 , 0.7058824 , 0.7058824 ]],\n",
       "\n",
       "       [[0.7019608 , 0.7019608 , 0.7019608 ],\n",
       "        [0.7058824 , 0.7058824 , 0.7058824 ],\n",
       "        [0.70980394, 0.70980394, 0.70980394],\n",
       "        ...,\n",
       "        [0.7058824 , 0.7058824 , 0.7058824 ],\n",
       "        [0.7058824 , 0.7058824 , 0.7058824 ],\n",
       "        [0.7058824 , 0.7058824 , 0.7058824 ]]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_data = ImageDataGenerator(rescale = 1.0/255).flow_from_directory(test_datapath,target_size = (150,150),batch_size = 2,classes = ['cats','bus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,Activation,MaxPooling2D,Dropout,Flatten,Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape= train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "# max pooling layer\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25)) \n",
    "# default value of stride = 1\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))# the o/p of 10 neurons will be summed together\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?model.fit_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/11\n",
      "5/5 [==============================] - 8s 2s/step - loss: 1.4862 - acc: 0.6000\n",
      "Epoch 2/11\n",
      "5/5 [==============================] - 6s 1s/step - loss: 1.9483 - acc: 0.3000\n",
      "Epoch 3/11\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.6233 - acc: 0.6000\n",
      "Epoch 4/11\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.6564 - acc: 0.9000\n",
      "Epoch 5/11\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.7777 - acc: 0.5000\n",
      "Epoch 6/11\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.6004 - acc: 0.6000\n",
      "Epoch 7/11\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.4742 - acc: 0.7000\n",
      "Epoch 8/11\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.7457 - acc: 0.6000\n",
      "Epoch 9/11\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.6433 - acc: 0.6000\n",
      "Epoch 10/11\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.4591 - acc: 0.7000\n",
      "Epoch 11/11\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.4839 - acc: 0.7000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23906661dd8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_data,steps_per_epoch = 5,epochs = 11)#steps_per_epoch = no.of batches = totnoofrecs/batchsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?model.predict_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = model.predict_generator(test_data,steps = 3)#steps = no.of test batches = totnoofrecs/batchsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5762256 , 0.4237744 ],\n",
       "       [0.41465825, 0.5853417 ],\n",
       "       [0.46413356, 0.5358664 ],\n",
       "       [0.47876447, 0.5212355 ],\n",
       "       [0.59568524, 0.40431476],\n",
       "       [0.57762885, 0.42237115]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(preds.shape[0]):\n",
    "    for j in range(preds.shape[1]):\n",
    "        if preds[i][j]>0.5:\n",
    "            preds[i][j] = 1\n",
    "        else:\n",
    "            preds[i][j] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test,test_labels = next(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test,test_labels = next(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test,test_labels = next(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#4 correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
