{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_datapath = 'F:\\\\Library\\\\Analytics Path\\\\Datasets\\\\01_CNN_Eg1\\\\data\\\\train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_datapath = 'F:\\\\Library\\\\Analytics Path\\\\Datasets\\\\01_CNN_Eg1\\\\data\\\\test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?ImageDataGenerator.flow_from_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data = ImageDataGenerator(rescale = 1.0/255).flow_from_directory(train_datapath,target_size = (224,224),batch_size = 10,classes = ['cats','bus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train,train_labels = next(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#works only without rescale option\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# plots images with labels within jupyter notebook\n",
    "def plots(ims, figsize=(12,6), rows=1, interp=False, titles=None):\n",
    "    if type(ims[0]) is np.ndarray:\n",
    "        ims = np.array(ims).astype(np.uint8)\n",
    "        if (ims.shape[-1] != 3):\n",
    "            ims = ims.transpose((0,2,3,1))\n",
    "    f = plt.figure(figsize=figsize)\n",
    "    cols = len(ims)//rows if len(ims) % 2 == 0 else len(ims)//rows + 1\n",
    "    for i in range(len(ims)):\n",
    "        sp = f.add_subplot(rows, cols, i+1)\n",
    "        sp.axis('Off')\n",
    "        if titles is not None:\n",
    "            sp.set_title(titles[i], fontsize=16)\n",
    "        plt.imshow(ims[i], interpolation=None if interp else 'none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plots(train,titles = train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAABqCAYAAABOIsyEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24240ecde10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 224, 224, 3)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.7019608 , 0.7019608 , 0.7019608 ],\n",
       "        [0.7019608 , 0.7019608 , 0.7019608 ],\n",
       "        [0.7058824 , 0.7058824 , 0.7058824 ],\n",
       "        ...,\n",
       "        [0.70980394, 0.70980394, 0.70980394],\n",
       "        [0.70980394, 0.70980394, 0.70980394],\n",
       "        [0.70980394, 0.70980394, 0.70980394]],\n",
       "\n",
       "       [[0.7019608 , 0.7019608 , 0.7019608 ],\n",
       "        [0.7019608 , 0.7019608 , 0.7019608 ],\n",
       "        [0.70980394, 0.70980394, 0.70980394],\n",
       "        ...,\n",
       "        [0.70980394, 0.70980394, 0.70980394],\n",
       "        [0.70980394, 0.70980394, 0.70980394],\n",
       "        [0.70980394, 0.70980394, 0.70980394]],\n",
       "\n",
       "       [[0.7019608 , 0.7019608 , 0.7019608 ],\n",
       "        [0.7058824 , 0.7058824 , 0.7058824 ],\n",
       "        [0.70980394, 0.70980394, 0.70980394],\n",
       "        ...,\n",
       "        [0.70980394, 0.70980394, 0.70980394],\n",
       "        [0.70980394, 0.70980394, 0.70980394],\n",
       "        [0.70980394, 0.70980394, 0.70980394]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.7058824 , 0.7058824 , 0.7058824 ],\n",
       "        [0.7058824 , 0.7058824 , 0.7058824 ],\n",
       "        [0.70980394, 0.70980394, 0.70980394],\n",
       "        ...,\n",
       "        [0.70980394, 0.70980394, 0.70980394],\n",
       "        [0.7058824 , 0.7058824 , 0.7058824 ],\n",
       "        [0.7058824 , 0.7058824 , 0.7058824 ]],\n",
       "\n",
       "       [[0.7019608 , 0.7019608 , 0.7019608 ],\n",
       "        [0.7058824 , 0.7058824 , 0.7058824 ],\n",
       "        [0.70980394, 0.70980394, 0.70980394],\n",
       "        ...,\n",
       "        [0.7058824 , 0.7058824 , 0.7058824 ],\n",
       "        [0.7058824 , 0.7058824 , 0.7058824 ],\n",
       "        [0.7058824 , 0.7058824 , 0.7058824 ]],\n",
       "\n",
       "       [[0.7019608 , 0.7019608 , 0.7019608 ],\n",
       "        [0.7019608 , 0.7019608 , 0.7019608 ],\n",
       "        [0.70980394, 0.70980394, 0.70980394],\n",
       "        ...,\n",
       "        [0.7058824 , 0.7058824 , 0.7058824 ],\n",
       "        [0.7058824 , 0.7058824 , 0.7058824 ],\n",
       "        [0.7058824 , 0.7058824 , 0.7058824 ]]], dtype=float32)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_data = ImageDataGenerator(rescale = 1.0/255).flow_from_directory(test_datapath,target_size = (224,224),batch_size = 6,classes = ['cats','bus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del vgg16_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg16_model = keras.applications.vgg16.VGG16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg16_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#input size is 224x224, so while reading data, resize to 224x224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.engine.training.Model"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(vgg16_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x24241291080>,\n",
       " <keras.layers.convolutional.Conv2D at 0x242410c0978>,\n",
       " <keras.layers.convolutional.Conv2D at 0x242411f0f60>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x24240f06e80>,\n",
       " <keras.layers.convolutional.Conv2D at 0x24240f06080>,\n",
       " <keras.layers.convolutional.Conv2D at 0x24241298668>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x24240eedd68>,\n",
       " <keras.layers.convolutional.Conv2D at 0x24240eed0b8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x242412d1ac8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x24240edeeb8>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x24240cddf98>,\n",
       " <keras.layers.convolutional.Conv2D at 0x24240cdde10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x2423f507860>,\n",
       " <keras.layers.convolutional.Conv2D at 0x24240c25cc0>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x24240bf1d68>,\n",
       " <keras.layers.convolutional.Conv2D at 0x24240bf1a58>,\n",
       " <keras.layers.convolutional.Conv2D at 0x24240c70588>,\n",
       " <keras.layers.convolutional.Conv2D at 0x24240c42a20>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x2423f41fc18>,\n",
       " <keras.layers.core.Flatten at 0x2423f41f358>,\n",
       " <keras.layers.core.Dense at 0x24240cee3c8>,\n",
       " <keras.layers.core.Dense at 0x242404536a0>,\n",
       " <keras.layers.core.Dense at 0x242401c4da0>]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg16_model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for layer in vgg16_model.layers[:-1]:\n",
    "    model.add(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "=================================================================\n",
      "Total params: 134,260,544\n",
      "Trainable params: 134,260,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.Dense at 0x2425afcc438>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to remove last layer: model.layers.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#to freeze all the weights of connections as they were in \n",
    "#original VGG16 model. \n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "#wts connecting last dense layer(which ll be added newly)\n",
    "#will be affected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Dense(2,activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 8194      \n",
      "=================================================================\n",
      "Total params: 134,268,738\n",
      "Trainable params: 8,194\n",
      "Non-trainable params: 134,260,544\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = opt,loss = 'categorical_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/11\n",
      "1/1 [==============================] - 6s 6s/step - loss: 1.2156 - acc: 0.5000\n",
      "Epoch 2/11\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.8072 - acc: 0.5000\n",
      "Epoch 3/11\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.7080 - acc: 0.5000\n",
      "Epoch 4/11\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.6712 - acc: 0.6000\n",
      "Epoch 5/11\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.6435 - acc: 0.7000\n",
      "Epoch 6/11\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.6190 - acc: 0.9000\n",
      "Epoch 7/11\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.5967 - acc: 0.9000\n",
      "Epoch 8/11\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.5759 - acc: 0.9000\n",
      "Epoch 9/11\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.5563 - acc: 0.9000\n",
      "Epoch 10/11\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.5378 - acc: 0.9000\n",
      "Epoch 11/11\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.5201 - acc: 0.9000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24240de2198>"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_data,steps_per_epoch =1,epochs = 11)#steps_per_epoch = no.of batches coming in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = model.predict_generator(test_data,steps = 1,verbose = 0) # steps = no.of test batches coming in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.39991033, 0.60008967],\n",
       "       [0.625493  , 0.37450695],\n",
       "       [0.4234733 , 0.5765267 ],\n",
       "       [0.5072728 , 0.49272725],\n",
       "       [0.71578836, 0.28421164],\n",
       "       [0.57867163, 0.4213284 ]], dtype=float32)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(preds.shape[0]):\n",
    "    for j in range(preds.shape[1]):\n",
    "        if preds[i][j]>0.5:\n",
    "            preds[i][j] = 1\n",
    "        else:\n",
    "            preds[i][j] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test,test_labels = next(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#50% accuracy\n",
    "#Large datasets and more no.of epochs can imporve the model's performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
